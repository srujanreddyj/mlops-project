{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vCJ3pvJKY_xV"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "### Problem\n",
        "\n",
        "In the project this week, we will build a machine learning text classifier to predict news categories from the news article text. \n",
        "\n",
        "1. We will iterate on classification models with increasing level of complexity and improved performance: N-gram models, pre-trained Transformer models, and third-party hosted Large Language Models (LLMs).\n",
        "\n",
        "2. We will look at the impact of labeled dataset size and composition on model performance. The labeled dataset will be used for training in case of N-gram models and pre-trained Transformers, and for selecting examples for in-context few-shot learning for LLMs.\n",
        "\n",
        "3. [advanced] As an extension, we will explore how to augment data efficiently to your existing training data (efficiency measured as improvement in performance normalized by volume of data augmented). \n",
        "\n",
        "Throughout the project there are suggested model architectures that we expect to work reasonably well for this problem. But if you wish to extend/modify any part of this pipeline, or explore new model architectures you should definitely feel free to do so.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4FNP8FSfZIed"
      },
      "source": [
        "## Step1: Prereqs & Installation\n",
        "\n",
        "Download & Import all the necessary libraries we need throughout the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1LsWxD0ZF3b"
      },
      "outputs": [],
      "source": [
        "# Install all the required dependencies for the project\n",
        "\n",
        "!pip install numpy\n",
        "!pip install scikit-learn\n",
        "!pip install sentence-transformers\n",
        "!pip install matplotlib\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yiDpaCRTZOKL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sjabbireddy/.pyenv/versions/3.10.0/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Package imports that will be needed for this project\n",
        "\n",
        "import numpy as np\n",
        "import json\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from pprint import pprint\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "\n",
        "# [TO BE IMPLEMENTED] \n",
        "# Add any other imports needed below depending on the model architectures you are using. For e.g.\n",
        "# from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p9asDVPMZlf3"
      },
      "outputs": [],
      "source": [
        "# Global Constants\n",
        "LABEL_SET = [\n",
        "    'Business',\n",
        "    'Sci/Tech',\n",
        "    'Software and Developement',\n",
        "    'Entertainment',\n",
        "    'Sports',\n",
        "    'Health',\n",
        "    'Toons',\n",
        "    'Music Feeds'\n",
        "]\n",
        "\n",
        "WORD_VECTOR_MODEL = 'glove-wiki-gigaword-100'\n",
        "SENTENCE_TRANSFORMER_MODEL = 'all-mpnet-base-v2'\n",
        "\n",
        "TRAIN_SIZE_EVALS = [500, 1000, 10000, 25000]\n",
        "EPS = 0.001\n",
        "SEED = 0\n",
        "\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gLu2IBiqZsgs"
      },
      "source": [
        "## Step 2: Download & Load Datasets \n",
        "\n",
        "[AG News](http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html) is a collection of more than 1 million news articles gathered from more than 2000 news sources by an academic news search engine. The news topic classification dataset & benchmark was first used in [Character-level Convolutional Networks for Text Classification (NIPS 2015)](https://arxiv.org/abs/1509.01626). The dataset has the text description (summary) of the news article along with some metadata. **For this project, we will use a slightly modified (cleaned up) version of this dataset** \n",
        "\n",
        "Schema:\n",
        "* Source - News publication source\n",
        "* URL - URL of the news article\n",
        "* Title - Title of the news article\n",
        "* Description - Summary description of the news article\n",
        "* Category (Label) - News category\n",
        "\n",
        "Sample row in this dataset:\n",
        "```\n",
        "{\n",
        "    'description': 'A capsule carrying solar material from the Genesis space '\n",
        "                'probe has made a crash landing at a US Air Force training '\n",
        "                'facility in the US state of Utah.',\n",
        "    'id': 86273,\n",
        "    'label': 'Entertainment',\n",
        "    'source': 'Voice of America',\n",
        "    'title': 'Capsule from Genesis Space Probe Crashes in Utah Desert',\n",
        "    'url': 'http://www.sciencedaily.com/releases/2004/09/040908090621.htm'\n",
        " }\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFGaBYdSZtqM"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "\n",
        "DIRECTORY_NAME = \"data\"\n",
        "DOWNLOAD_URL = 'https://corise-mlops.s3.us-west-2.amazonaws.com/project1/agnews.zip'\n",
        "\n",
        "def download_dataset():\n",
        "    \"\"\"\n",
        "    Download the dataset. The zip contains three files: train.json, test.json and unlabeled.json \n",
        "    \"\"\"\n",
        "    http_response = urlopen(DOWNLOAD_URL)\n",
        "    zipfile = ZipFile(BytesIO(http_response.read()))\n",
        "    zipfile.extractall(path=DIRECTORY_NAME)\n",
        "\n",
        "# Expensive operation so we should just do this once\n",
        "download_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zYnT4BIcZ5vX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded Dataset train with 25000 rows\n",
            "Loaded Dataset test with 5000 rows\n",
            "Loaded Dataset augment with 150000 rows\n",
            "\n",
            "Example train row:\n",
            "\n",
            "{'description': 'A capsule carrying solar material from the Genesis space '\n",
            "                'probe has made a crash landing at a US Air Force training '\n",
            "                'facility in the US state of Utah.',\n",
            " 'id': 86273,\n",
            " 'label': 'Entertainment',\n",
            " 'source': 'Voice of America',\n",
            " 'title': 'Capsule from Genesis Space Probe Crashes in Utah Desert',\n",
            " 'url': 'http://www.sciencedaily.com/releases/2004/09/040908090621.htm'}\n",
            "\n",
            "Example test row:\n",
            "\n",
            "{'description': 'European Union regulators will decide Tuesday whether Oracle '\n",
            "                \"Corp.'s hostile \\\\$7.7 billion bid for rival business \"\n",
            "                \"software concern PeopleSoft Inc. can proceed, the EU's \"\n",
            "                'antitrust chief said Friday.',\n",
            " 'id': 278781,\n",
            " 'label': 'Sci/Tech',\n",
            " 'source': 'Washington Post Tech',\n",
            " 'title': \"EU to Rule Tuesday on Oracle's Bid for PeopleSoft\",\n",
            " 'url': 'http://www.washingtonpost.com/wp-dyn/articles/A53747-2004Oct22.html?nav=rss_technology'}\n"
          ]
        }
      ],
      "source": [
        "Datasets = {}\n",
        "\n",
        "for ds in ['train', 'test', 'augment']:\n",
        "    with open('data/{}.json'.format(ds), 'r') as f:\n",
        "        Datasets[ds] = json.load(f)\n",
        "    print(\"Loaded Dataset {0} with {1} rows\".format(ds, len(Datasets[ds])))\n",
        "\n",
        "print(\"\\nExample train row:\\n\")\n",
        "pprint(Datasets['train'][0])\n",
        "\n",
        "print(\"\\nExample test row:\\n\")\n",
        "pprint(Datasets['test'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcwebhuYZ8Kb"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = [], []\n",
        "X_test, Y_true = [], []\n",
        "X_augment, Y_augment = [], []\n",
        "\n",
        "for row in Datasets['train']:\n",
        "    X_train.append(row['description'])\n",
        "    Y_train.append(row['label'])\n",
        "\n",
        "for row in Datasets['test']:\n",
        "    X_test.append(row['description'])\n",
        "    Y_true.append(row['label'])\n",
        "\n",
        "for row in Datasets['augment']:\n",
        "    X_augment.append(row['description'])\n",
        "    Y_augment.append(row['label'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KoayaMr8aBwp"
      },
      "source": [
        "## Step 3: [Modeling part 1] N-gram model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2zIahH6aHJ9"
      },
      "outputs": [],
      "source": [
        "models = {}\n",
        "\n",
        "for n in TRAIN_SIZE_EVALS:\n",
        "    print(\"Evaluating for training data size = {}\".format(n))\n",
        "    X_train_i = X_train[:n]\n",
        "    Y_train_i = Y_train[:n]\n",
        "\n",
        "    \"\"\"\n",
        "    [TO BE IMPLEMENTED]\n",
        "        \n",
        "    Goal: initialized below is a dummy sklearn Pipeline object with no steps.\n",
        "    You have to replace it with a pipeline object which contains at least two steps:\n",
        "    (1) mapping the input document to an N-gram feature extractor. You can use feature extractors\n",
        "        provided by sklearn out of the box (e.g. CountVectorizer, TfidfTransformer)\n",
        "    (2) a classifier that predicts the class label using the feature output of first step\n",
        "\n",
        "    You can add other steps to preproces, post-process your data as you see fit. \n",
        "    You can also try any sklearn model architecture you want, but a linear classifier\n",
        "    will do just fine to start with\n",
        "\n",
        "    e.g. \n",
        "    pipeline = Pipeline([\n",
        "        ('featurizer', <your WordVectorFeaturizer class instance here>),\n",
        "        ('classifier', <your sklearn classifier class instance here>)\n",
        "    ])\n",
        "\n",
        "    Reference: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
        "    \"\"\"\n",
        "    pipeline = Pipeline()\n",
        "    \n",
        "    # train\n",
        "    pipeline.fit(X_train_i, Y_train_i)\n",
        "    # predict\n",
        "    Y_pred_i = pipeline.predict(X_test)\n",
        "    # record results\n",
        "    models[n] = {\n",
        "        'pipeline': pipeline,\n",
        "        'test_predictions': Y_pred_i,\n",
        "        'accuracy': accuracy_score(Y_true, Y_pred_i),\n",
        "        'f1': f1_score(Y_true, Y_pred_i, average='weighted'),\n",
        "        'errors': sum([x != y for (x, y) in zip(Y_true, Y_pred_i)])\n",
        "    }\n",
        "    print(\"Accuracy on test set: {}\".format(accuracy_score(Y_true, Y_pred_i)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OBxVNbWBaMhc"
      },
      "source": [
        "## Step 4: [Modeling part 2] Pretrained Transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27TJGTZfavys"
      },
      "outputs": [],
      "source": [
        "# Initialize the pretrained transformer model\n",
        "sentence_transformer_model = SentenceTransformer(\n",
        "    'sentence-transformers/{model}'.format(model=SENTENCE_TRANSFORMER_MODEL))\n",
        "\n",
        "# Sanity check\n",
        "example_encoding = sentence_transformer_model.encode(\n",
        "    \"This is an example sentence\",\n",
        "    normalize_embeddings=True\n",
        ")\n",
        "\n",
        "print(example_encoding)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de0oQW1raJzY"
      },
      "outputs": [],
      "source": [
        "class TransformerFeaturizer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, dim, sentence_transformer_model):\n",
        "        self.dim = dim\n",
        "        self.sentence_transformer_model = sentence_transformer_model\n",
        "        # you can add any other params to be passed to the constructor here\n",
        "\n",
        "    #estimator. Since we don't have to learn anything in the featurizer, this is a no-op\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    #transformation: return the encoding of the document as returned by the transformer model \n",
        "    def transform(self, X, y=None):\n",
        "        X_t = []\n",
        "        \"\"\"\n",
        "        [TO BE IMPLEMENTED]\n",
        "        \n",
        "        Goal: TransformerFeaturizer's transform() method converts the raw text document\n",
        "        into a feature vector to be passed as input to the classifier.\n",
        "            \n",
        "        Given below is a dummy implementation that always maps it to a zero vector.\n",
        "        You have to implement this function so it uses computes a document embedding\n",
        "        of the input document using self.sentence_transformer_model. \n",
        "        This will be our feature representation of the document\n",
        "        \"\"\"\n",
        "        for doc in X:\n",
        "            # TODO: replace this dummy implementation\n",
        "            X_t.append(np.zeros(self.dim))\n",
        "        return X_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1nwMri8aeFi"
      },
      "outputs": [],
      "source": [
        "models_v2 = {}\n",
        "for n in TRAIN_SIZE_EVALS:\n",
        "    print(\"Evaluating for training data size = {}\".format(n))\n",
        "    X_train_i = X_train[:n]\n",
        "    Y_train_i = Y_train[:n]\n",
        "\n",
        "    \"\"\"\n",
        "    [TO BE IMPLEMENTED]\n",
        "        \n",
        "    Goal: initialized below is a dummy sklearn Pipeline object with no steps.\n",
        "    You have to replace it with a pipeline object which contains at least two steps:\n",
        "    (1) mapping the input document to a feature vector (using TransformerFeaturizer)\n",
        "    (2) a classifier that predicts the class label using the feature output of first step\n",
        "\n",
        "    You can add other steps to preproces, post-process your data as you see fit. \n",
        "    You can also try any sklearn model architecture you want, but a linear classifier\n",
        "    will do just fine to start with\n",
        "\n",
        "    e.g. \n",
        "    pipeline = Pipeline([\n",
        "        ('featurizer', <your TransformerFeaturizer class instance here>),\n",
        "        ('classifier', <your sklearn classifier class instance here>)\n",
        "    ])\n",
        "    \"\"\"\n",
        "    pipeline = Pipeline()\n",
        "\n",
        "    # train\n",
        "    pipeline.fit(X_train_i, Y_train_i)\n",
        "    # predict\n",
        "    Y_pred_i = pipeline.predict(X_test)\n",
        "    # record results\n",
        "    models_v2[n] = {\n",
        "        'pipeline': pipeline,\n",
        "        'test_predictions': Y_pred_i,\n",
        "        'accuracy': accuracy_score(Y_true, Y_pred_i),\n",
        "        'f1': f1_score(Y_true, Y_pred_i, average='weighted'),\n",
        "        'errors': sum([x != y for (x, y) in zip(Y_true, Y_pred_i)])\n",
        "    }\n",
        "    print(\"Accuracy on test set: {}\".format(accuracy_score(Y_true, Y_pred_i)))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xw89vQkE5woo"
      },
      "source": [
        "## Step 5: [Modeling part 3] Large Language Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSijGuIc5yX4"
      },
      "outputs": [],
      "source": [
        "# Here's a couple of code snippets to help you familiarize with how to generate labels with LLMs using langchain,\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import LLMResult, HumanMessage, Generation\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    max_tokens=1000,\n",
        "    temperature=0.0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5-u93SS50ip"
      },
      "outputs": [],
      "source": [
        "\n",
        "zero_shot_prompt_template = \"\"\"\n",
        "You are an expert at judging the sentiment of tweets. \n",
        "Your job is to categorize the sentiment of a given tweet into one of three categories: Positive, Negative, Neutral.\n",
        "\n",
        "Tweet: {tweet}\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "\n",
        "prompt = zero_shot_prompt_template.format(\n",
        "    tweet=\"Yesss! I love machine learning\"\n",
        ")\n",
        "\n",
        "result = llm.generate([[HumanMessage(content=prompt)]])\n",
        "print(result.generations[0][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OovRQRuE52Tm"
      },
      "outputs": [],
      "source": [
        "\n",
        "few_shot_prompt_template = \"\"\"\n",
        "You are an expert at judging the sentiment of tweets. \n",
        "Your job is to categorize the sentiment of a given tweet into one of three categories: Positive, Negative, Neutral.\n",
        "\n",
        "Some example tweets along with the correct sentiment are shown below.\n",
        "\n",
        "Tweet: Another big happy 18th birthday to my partner in crime. I love u very much!\n",
        "Sentiment: Positive\n",
        "\n",
        "Tweet: The more I use this application, the more I dislike it. It's slow and full of bugs.\n",
        "Sentiment: Negative\n",
        "\n",
        "Tweet: #Dreamforce Returns to San Francisco for 20th Anniversary. Learn more: http://bit.ly/3AgwO0H\n",
        "Sentiment: Neutral\n",
        "\n",
        "Now I want you to label the following example: \n",
        "Tweet: {tweet}\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "\n",
        "prompt = few_shot_prompt_template.format(\n",
        "    tweet=\"I like chocolate\"\n",
        ")\n",
        "\n",
        "result = llm.generate([[HumanMessage(content=prompt)]])\n",
        "print(result.generations[0][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "by3AxCi058qH"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "\n",
        "class LLMClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, llm_model, prompt_template):\n",
        "        self.llm_model = llm_model\n",
        "        self.prompt_template = prompt_template\n",
        "\n",
        "    #This will be called during the training step\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    #This will be called during inference.\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        [TO BE IMPLEMENTED]\n",
        "        \n",
        "        Goal: LLMClassifier's predict() method constructs the final prompt input\n",
        "        for the LLM for each x in X, using the prompt template.\n",
        "\n",
        "        You have to implement this function so it does the following:\n",
        "        1. Construct the final prompt for the LLM\n",
        "        2. Call `self.llm_model` to generate the completion (label) for the prompt\n",
        "        3. Do any post-processing/response parsing to fetch the label from the LLM response\n",
        "        \"\"\"\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVemE-2R5-xN"
      },
      "outputs": [],
      "source": [
        "# Zero-shot classification pipeline with LLMs\n",
        "\n",
        "models_v3 = {}\n",
        "\n",
        "\"\"\"\n",
        "[TO BE IMPLEMENTED]\n",
        "        \n",
        "Goal: initialized below is a dummy sklearn Pipeline object with no steps.\n",
        "You have to replace it with a pipeline object which uses the `LLMClassifier` you have implemented \n",
        "above to perform zero-shot classification on the test set.\n",
        "\n",
        "You can add other steps to preproces, post-process your data as you see fit. \n",
        "\n",
        "\"\"\"\n",
        "pipeline = Pipeline()\n",
        "\n",
        "# train\n",
        "pipeline.fit(X_train_i, Y_train_i)\n",
        "# predict\n",
        "Y_pred_i = pipeline.predict(X_test)\n",
        "# record results\n",
        "models_v3[\"zero-shot\"] = {\n",
        "    'test_predictions': Y_pred_i,\n",
        "    'accuracy': accuracy_score(Y_true, Y_pred_i),\n",
        "    'f1': f1_score(Y_true, Y_pred_i, average='weighted'),\n",
        "    'errors': sum([x != y for (x, y) in zip(Y_true, Y_pred_i)])\n",
        "}\n",
        "print(\"Accuracy on test set: {}\".format(accuracy_score(Y_true, Y_pred_i)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvCbruqf6ASV"
      },
      "outputs": [],
      "source": [
        "# Few-shot classification with LLMs\n",
        "\n",
        "\"\"\"\n",
        "[TO BE IMPLEMENTED]\n",
        "        \n",
        "Goal: initialized below is a dummy sklearn Pipeline object with no steps.\n",
        "You have to replace it with a pipeline object which uses the `LLMClassifier` you have implemented \n",
        "above to perform few-shot classification on the test set.\n",
        "\n",
        "With few-shot classification, you can pass upto 5 demonstration examples as part of the prompt \n",
        "to the LLM. You can add other steps to preproces, post-process your data as you see fit. \n",
        "\n",
        "\"\"\"\n",
        "pipeline = Pipeline()\n",
        "\n",
        "# train\n",
        "pipeline.fit(X_train_i, Y_train_i)\n",
        "# predict\n",
        "Y_pred_i = pipeline.predict(X_test)\n",
        "# record results\n",
        "models_v3[\"few-shot\"] = {\n",
        "    'test_predictions': Y_pred_i,\n",
        "    'accuracy': accuracy_score(Y_true, Y_pred_i),\n",
        "    'f1': f1_score(Y_true, Y_pred_i, average='weighted'),\n",
        "    'errors': sum([x != y for (x, y) in zip(Y_true, Y_pred_i)])\n",
        "}\n",
        "print(\"Accuracy on test set: {}\".format(accuracy_score(Y_true, Y_pred_i)))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qdQDQ8Sla2u3"
      },
      "source": [
        "## Step 5: Report Results from previous two steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpKaurcHa0Vh"
      },
      "outputs": [],
      "source": [
        "# Report results\n",
        "\n",
        "print(\"N-gram Models: \")\n",
        "for train_size, result in models.items():\n",
        "    print(\"Train size: {0}  |  Accuracy: {1}  |  F1 score: {3} |  Num errors: {4}\".format(\n",
        "        train_size,\n",
        "        result['accuracy'],\n",
        "        result['f1'],\n",
        "        result['errors']\n",
        "    ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rztr78oD6EQp"
      },
      "outputs": [],
      "source": [
        "print(\"Pretrained Transformer Models: \")\n",
        "for train_size, result in models_v2.items():\n",
        "    print(\"Train size: {0}  |  Accuracy: {1}  |  F1 score: {3} |  Num errors: {4}\".format(\n",
        "        train_size,\n",
        "        result['accuracy'],\n",
        "        result['f1'],\n",
        "        result['errors']\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_sQOJW36Cqr"
      },
      "outputs": [],
      "source": [
        "print(\"Large Language Models: \")\n",
        "for mode, result in models_v3.items():\n",
        "    print(\"Mode: {0}  |  Accuracy: {1}  |  F1 score: {3} |  Num errors: {4}\".format(\n",
        "        mode,\n",
        "        result['accuracy'],\n",
        "        result['f1'],\n",
        "        result['errors']\n",
        "    ))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4v882hLIa6gR"
      },
      "source": [
        "## Step 6: Data Augmentation [Optional]\n",
        "\n",
        "In this section, we want to explore how to augment data efficiently to your existing training data. This is a very empirical exercise with a less well-defined playbook which means this section of the project is going to be open ended. Let us first understand what we mean by efficiency here, and why it matters:\n",
        "\n",
        "### Performance Gain (G):\n",
        "We will measure performance gain from data augmentation as the improvement in model accuracy (reduction in num. errors) on the Test dataset as defined above. \n",
        "\n",
        "### Budget (K):\n",
        "We will measure \"budget\" as the number of additional rows augmentated to the original training dataset.  In this project, the universe of data from which you will select to add to your training set is Datasets['augment'] (and downstream X_augment, Y_augment).\n",
        "\n",
        "This data is already labeled of course, but in most real-world scenarios the additional data is typically unlabeled. In order to augment it to your training data, you have to get it annotated which incurs some cost in time & money. This is the motivation to consider budget as a metric.\n",
        "\n",
        "### Efficiency (E = G / K): \n",
        "Efficiency = Performance Gain (Reduction in num errors in test set) / Budget (Number of additional rows augmented to the training dataset)\n",
        "\n",
        "We want to get the maximum gain in performance, while incurring minimum annotation cost."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-a-kk3Pk6Jx-"
      },
      "source": [
        "\n",
        "\n",
        "We can always sample more data at random from the augmentation set, and this is probably the first thing to try. Can we be more intelligent with the data we choose to augment to the training dataset?\n",
        "\n",
        "**Idea 1**: Look at the test errors that the current model is making. How can this help us guide our \"data collection\" for augmentation? One possible idea is to select examples from the augmentation dataset that are similar to these errors and add them to the training data. Similarity can be approximated in many ways:\n",
        "1. [Jaccard distance between two texts](https://studymachinelearning.com/jaccard-similarity-text-similarity-metric-in-nlp/)\n",
        "2. L2 distance between mean word vectors (we already compute these features for the entire dataset using WordVectorFeaturizer)\n",
        "3. L2 distance between sentence transformer embedding (we already compute these features for the entire dataset using TransformerFeaturizer)\n",
        "  \n",
        "\n",
        "**Idea 2**: Compute model's predictions on the augmentation dataset, and include those examples to the training dataset that the model finds \"hard\" ? (a proxy for this would be to look at cases where the output score distribution across all labels has nearly identical scores for top two or three labels).\n",
        "\n",
        "**Idea 3**: Look at the test errors that the current model is making, and the distribution of these errors across labels. Select examples from the augmentation dataset that belong to these classes - adding more training data for labels that the curent model does not do well on, can improve performance (assuming label quality is good)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UVN6r0abKHI"
      },
      "outputs": [],
      "source": [
        "# Examine current test errors\n",
        "test_errors = []\n",
        "Y_pred_i = models[25000]['test_predictions']\n",
        "\n",
        "for idx, label in enumerate(Y_true):\n",
        "    if label != Y_pred_i[idx]:\n",
        "        test_errors.append((X_test[idx], label,  Y_pred_i[idx]))\n",
        "\n",
        "print(\"Number of errors in the test set: {}\".format(len(test_errors)))\n",
        "print(\"Example errors: [example, true label, predicted label]\")\n",
        "for i in range(10):\n",
        "    print(test_errors[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2LCwb4ibYsV"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "[TO BE IMPLEMENTED]\n",
        "\n",
        "Your additional data augmentation explorations go here\n",
        "\n",
        "For instance, the pseudocode for Idea (1) might look like the following:\n",
        "\n",
        "Augmented = {}\n",
        "For e in test_errors:\n",
        "   1. X_nn, y_nn = k nearest neighbors to (e) from X_augment, y_augment\n",
        "   2. Add each (x, y) from (X_nn, y_nn) to Augmented\n",
        "\n",
        "Add the Augmented examples to the training set\n",
        "Train the new model and record performance improvements\n",
        "\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
