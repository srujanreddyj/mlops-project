{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"vCJ3pvJKY_xV"},"source":["# Introduction\n","\n","### Problem\n","\n","In the project this week, we will build a machine learning text classifier to predict news categories from the news article text. \n","\n","1. We will iterate on classification models with increasing level of complexity and improved performance: N-gram models, pre-trained Transformer models, and third-party hosted Large Language Models (LLMs).\n","\n","2. We will look at the impact of labeled dataset size and composition on model performance. The labeled dataset will be used for training in case of N-gram models and pre-trained Transformers, and for selecting examples for in-context few-shot learning for LLMs.\n","\n","3. [advanced] As an extension, we will explore how to augment data efficiently to your existing training data (efficiency measured as improvement in performance normalized by volume of data augmented). \n","\n","Throughout the project there are suggested model architectures that we expect to work reasonably well for this problem. But if you wish to extend/modify any part of this pipeline, or explore new model architectures you should definitely feel free to do so.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4FNP8FSfZIed"},"source":["## Step1: Prereqs & Installation\n","\n","Download & Import all the necessary libraries we need throughout the project."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67844,"status":"ok","timestamp":1686284607190,"user":{"displayName":"","userId":""},"user_tz":300},"id":"l1LsWxD0ZF3b","outputId":"ec3f04a5-31a6-4e6a-89f1-b61420b6a9b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentence-transformers\n","  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers)\n","  Downloading transformers-4.30.0-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.65.0)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.2+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.22.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.10.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n","Collecting sentencepiece (from sentence-transformers)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence-transformers)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.10.31)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m115.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (8.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=3109ee8f41653f1d8e174ee8c326a915cc773dd8a2688919bb5360dcef4bb3b9\n","  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n","Successfully built sentence-transformers\n","Installing collected packages: tokenizers, sentencepiece, safetensors, huggingface-hub, transformers, sentence-transformers\n","Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 sentence-transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.30.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting langchain\n","  Downloading langchain-0.0.194-py3-none-any.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n","Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n","  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n","Collecting langchainplus-sdk>=0.0.6 (from langchain)\n","  Downloading langchainplus_sdk-0.0.7-py3-none-any.whl (22 kB)\n","Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n","Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n","  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n","Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n","Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: mypy-extensions, multidict, marshmallow, frozenlist, async-timeout, yarl, typing-inspect, openapi-schema-pydantic, marshmallow-enum, langchainplus-sdk, aiosignal, dataclasses-json, aiohttp, langchain\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.7 frozenlist-1.3.3 langchain-0.0.194 langchainplus-sdk-0.0.7 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0 yarl-1.9.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openai\n","  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n","Installing collected packages: openai\n","Successfully installed openai-0.27.8\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.15.4-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-1.25.1-py2.py3-none-any.whl (206 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.7/206.7 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n","Collecting pathtools (from wandb)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=38adb14694d37d1e3c8965026cb8c1c73eb67b2c8a69df07698c2c9d684d31d3\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built pathtools\n","Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.25.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.4\n"]}],"source":["# Install all the required dependencies for the project\n","\n","!pip install numpy\n","!pip install scikit-learn\n","!pip install sentence-transformers\n","!pip install matplotlib\n","!pip install langchain\n","!pip install openai\n","!pip install wandb"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":8301,"status":"ok","timestamp":1686284615474,"user":{"displayName":"","userId":""},"user_tz":300},"id":"yiDpaCRTZOKL"},"outputs":[],"source":["# Package imports that will be needed for this project\n","\n","import os\n","import numpy as np\n","import json\n","from collections import Counter\n","from sklearn.metrics import accuracy_score, f1_score\n","from sentence_transformers import SentenceTransformer\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from pprint import pprint\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n","\n","# [TO BE IMPLEMENTED] \n","# Add any other imports needed below depending on the model architectures you are using. For e.g.\n","# from sklearn.linear_model import LogisticRegression"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1686284617291,"user":{"displayName":"","userId":""},"user_tz":300},"id":"p9asDVPMZlf3"},"outputs":[],"source":["with open('apikey.json') as f:\n","   apikey = json.load(f)\n","\n","OPENAI_API_KEY = apikey['API_KEY_USER']\n","\n","\n","# Global Constants\n","LABEL_SET = [\n","    'Business',\n","    'Sci/Tech',\n","    'Software and Developement',\n","    'Entertainment',\n","    'Sports',\n","    'Health',\n","    'Toons',\n","    'Music Feeds'\n","]\n","\n","WORD_VECTOR_MODEL = 'glove-wiki-gigaword-100'\n","SENTENCE_TRANSFORMER_MODEL = 'all-mpnet-base-v2'\n","\n","TRAIN_SIZE_EVALS = [500, 1000, 10000, 25000]\n","EPS = 0.001\n","SEED = 0\n","\n","np.random.seed(SEED)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gLu2IBiqZsgs"},"source":["## Step 2: Download & Load Datasets \n","\n","[AG News](http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html) is a collection of more than 1 million news articles gathered from more than 2000 news sources by an academic news search engine. The news topic classification dataset & benchmark was first used in [Character-level Convolutional Networks for Text Classification (NIPS 2015)](https://arxiv.org/abs/1509.01626). The dataset has the text description (summary) of the news article along with some metadata. **For this project, we will use a slightly modified (cleaned up) version of this dataset** \n","\n","Schema:\n","* Source - News publication source\n","* URL - URL of the news article\n","* Title - Title of the news article\n","* Description - Summary description of the news article\n","* Category (Label) - News category\n","\n","Sample row in this dataset:\n","```\n","{\n","    'description': 'A capsule carrying solar material from the Genesis space '\n","                'probe has made a crash landing at a US Air Force training '\n","                'facility in the US state of Utah.',\n","    'id': 86273,\n","    'label': 'Entertainment',\n","    'source': 'Voice of America',\n","    'title': 'Capsule from Genesis Space Probe Crashes in Utah Desert',\n","    'url': 'http://www.sciencedaily.com/releases/2004/09/040908090621.htm'\n"," }\n","```\n","\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":8514,"status":"ok","timestamp":1686284631840,"user":{"displayName":"","userId":""},"user_tz":300},"id":"jFGaBYdSZtqM"},"outputs":[],"source":["from urllib.request import urlopen\n","from io import BytesIO\n","from zipfile import ZipFile\n","\n","DIRECTORY_NAME = \"data\"\n","DOWNLOAD_URL = 'https://corise-mlops.s3.us-west-2.amazonaws.com/project1/agnews.zip'\n","\n","def download_dataset():\n","    \"\"\"\n","    Download the dataset. The zip contains three files: train.json, test.json and unlabeled.json \n","    \"\"\"\n","    http_response = urlopen(DOWNLOAD_URL)\n","    zipfile = ZipFile(BytesIO(http_response.read()))\n","    zipfile.extractall(path=DIRECTORY_NAME)\n","\n","# Expensive operation so we should just do this once\n","download_dataset()"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2470,"status":"ok","timestamp":1686287236691,"user":{"displayName":"","userId":""},"user_tz":300},"id":"zYnT4BIcZ5vX","outputId":"4c0c6d49-fbf9-4230-cbd4-42c7c0fcfb98"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded Dataset train\n","Loaded Dataset test_mini\n","Loaded Dataset augment\n","\n","Example train row:\n","\n","{'description': 'A capsule carrying solar material from the Genesis space '\n","                'probe has made a crash landing at a US Air Force training '\n","                'facility in the US state of Utah.',\n"," 'id': 86273,\n"," 'label': 'Entertainment',\n"," 'source': 'Voice of America',\n"," 'title': 'Capsule from Genesis Space Probe Crashes in Utah Desert',\n"," 'url': 'http://www.sciencedaily.com/releases/2004/09/040908090621.htm'}\n","\n","Example test row:\n","\n","{'description': \"AP - Denny Neagle's contract was terminated by the Colorado \"\n","                'Rockies on Monday, three days after the oft-injured pitcher '\n","                'was cited for solicitation.',\n"," 'id': 116767,\n"," 'label': 'Sports',\n"," 'source': 'Yahoo Sports',\n"," 'title': \"Rockies Terminate Neagle's Contract (AP)\",\n"," 'url': 'http://us.rd.yahoo.com/dailynews/rss/sports/*http://story.news.yahoo.com/news?tmpl=story2 '\n","        'u=/ap/20041207/ap_on_sp_ba_ne/bbn_rockies_neagle'}\n"]}],"source":["Datasets = {}\n","\n","for ds in ['train', 'test_mini', 'augment']:\n","    with open('data/{}.json'.format(ds), 'r') as f:\n","        if ds == 'test_mini':\n","          Datasets['test'] = json.load(f)\n","        else:\n","          Datasets[ds] = json.load(f)\n","    print(\"Loaded Dataset {0}\".format(ds))\n","\n","print(\"\\nExample train row:\\n\")\n","pprint(Datasets['train'][0])\n","\n","print(\"\\nExample test row:\\n\")\n","pprint(Datasets['test'][0])"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":204,"status":"ok","timestamp":1686287579827,"user":{"displayName":"","userId":""},"user_tz":300},"id":"TcwebhuYZ8Kb"},"outputs":[],"source":["X_train, Y_train = [], []\n","X_test, Y_true = [], []\n","X_augment, Y_augment = [], []\n","\n","for row in Datasets['train']:\n","    X_train.append(row['description'])\n","    Y_train.append(row['label'])\n","\n","for row in Datasets['test']:\n","    X_test.append(row['description'])\n","    Y_true.append(row['label'])\n","\n","for row in Datasets['augment']:\n","    X_augment.append(row['description'])\n","    Y_augment.append(row['label'])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"KoayaMr8aBwp"},"source":["## Step 3: [Modeling part 1] N-gram model\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18564,"status":"ok","timestamp":1686284657658,"user":{"displayName":"","userId":""},"user_tz":300},"id":"n2zIahH6aHJ9","outputId":"4ef48815-3647-47b7-906c-35b99b4df278"},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluating for training data size = 500\n","Accuracy on test set: 0.3434\n","Evaluating for training data size = 1000\n","Accuracy on test set: 0.491\n","Evaluating for training data size = 10000\n","Accuracy on test set: 0.6474\n","Evaluating for training data size = 25000\n","Accuracy on test set: 0.7016\n"]}],"source":["models = {}\n","\n","for n in TRAIN_SIZE_EVALS:\n","    print(\"Evaluating for training data size = {}\".format(n))\n","    X_train_i = X_train[:n]\n","    Y_train_i = Y_train[:n]\n","\n","    \"\"\"\n","    [TO BE IMPLEMENTED]\n","        \n","    Goal: initialized below is a dummy sklearn Pipeline object with no steps.\n","    You have to replace it with a pipeline object which contains at least two steps:\n","    (1) mapping the input document to an N-gram feature extractor. You can use feature extractors\n","        provided by sklearn out of the box (e.g. CountVectorizer, TfidfTransformer)\n","    (2) a classifier that predicts the class label using the feature output of first step\n","\n","    You can add other steps to preproces, post-process your data as you see fit. \n","    You can also try any sklearn model architecture you want, but a linear classifier\n","    will do just fine to start with\n","\n","    e.g. \n","    pipeline = Pipeline([\n","        ('featurizer', <your WordVectorFeaturizer class instance here>),\n","        ('classifier', <your sklearn classifier class instance here>)\n","    ])\n","\n","    Reference: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n","    \"\"\"\n","    pipeline = Pipeline([\n","        ('vect', CountVectorizer()),\n","        ('tfidf', TfidfTransformer()),\n","        ('clf', LogisticRegression(max_iter=1000, C=0.1))\n","    ])\n","    \n","    # train\n","    pipeline.fit(X_train_i, Y_train_i)\n","    # predict\n","    Y_pred_i = pipeline.predict(X_test)\n","    # record results\n","    models[n] = {\n","        'pipeline': pipeline,\n","        'test_predictions': Y_pred_i,\n","        'accuracy': accuracy_score(Y_true, Y_pred_i),\n","        'f1': f1_score(Y_true, Y_pred_i, average='weighted'),\n","        'errors': sum([x != y for (x, y) in zip(Y_true, Y_pred_i)])\n","    }\n","    print(\"Accuracy on test set: {}\".format(accuracy_score(Y_true, Y_pred_i)))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"7b06DVbbY4Cr"},"source":["Side-Note: \n","Recieved following error for training data size = 10000 and above \n","/Users/sjabbireddy/.pyenv/versions/3.10.0/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","The error message says that the LogisticRegression object failed to converge after a certain number of iterations. This can happen for a number of reasons, including:\n","* The data is not linearly separable.\n","* The data is too noisy.\n","* The regularization parameter is too high.\n","\n","To fix this error, following are the options:\n","\n","* Increase the number of iterations.\n","* Use a different regularization parameter.\n","* Use a different algorithm, such as a decision tree or a random forest.\n","\n","Here are some specific changes you can make:\n","\n","* Change the max_iter parameter of the LogisticRegression object to a higher value.\n","* Change the C parameter of the LogisticRegression object to a lower value.\n","* Use a different algorithm, such as a decision tree or a random forest.\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1686284657658,"user":{"displayName":"","userId":""},"user_tz":300},"id":"LIq2PmBoY4Cr"},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"OBxVNbWBaMhc"},"source":["## Step 4: [Modeling part 2] Pretrained Transformer model"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["6128e9f3993544c0967b459aff338043","0384383090b540b49b87c0662e11ae27","30206105d1dd44a08a7f273df91dcb58","2cb7e553870d4f1fbf10d281fb0204fe","2481382d29194555b3c07490e4b7c6c3","a38d9789009c4eb9af2ab6eb1c084675","3c19dcdee0a24611b4f6373f6bda11d4","a1545436a1b24e7dbb8a7649f043f51d","ea9550f524124539be002af02a679256","6a57b192eeec46f3b304a63294df723a","f654477856014076b6f39c985d227c88","909daed29b91479cb960d637f6de31ed","6070cfde65124e9e908219044e2abd43","602eb03787b1446eade6e083ec913f60","083391f721584cc89829bc9065d18119","1ba315543b134766bfd54c14e96170b8","cb3ba136cdc2465c8e058725fe920f2b","6c7c752986d64c559d29e6a53143f232","548bb2407766465eacc5e211fc740ea6","aac62ff40b7742bda6cc627eec331b34","294508e886d747269b8dd1871746eb62","4e8c0b86106a44f58f079200e8b1bdcf","b13b0e0ef95847058b2ed145f5f1e5fc","43859ef9bdb04f938e21d5d347b78e6b","1cb4d447392b470fb1133a6695bc1327","11038e9233654ca381788e372596ea06","cae36db61aa645d58e644cf2a8f7d8bf","7cde5ee78d574b0a9014df9b56088f02","12f2ca96d9124b559b325544335243a2","e1f99a3aa74d4802b969362dfefdbe0f","d9dab577cb8b4a4088bff883dc410a8f","8f69bbf81d524cd1858b429cfdcf90f7","cd97c277505f433e9aae1c35e9fbc881","6d16a5b6a4a24d48a05853548067d191","8aeadeebe25a417fa8159a453eae90ab","0cde3b3731e548209330c4ed68c3ebbe","f7829974d77a469786ee3b99fc7508a4","2805b644dcce45d8941ef373be17b3ab","f242e29d8870458fa574c029d727dbf8","4f984c50813a4c6c9f8f7b5f4debf52d","aa6062fde486403eb74a93c36c76d7a9","16a91b33e5d74539884a571d8883eb17","b29dfe2ce98246fa971f8eb399271cc4","aa3caed35cad44e59099d3ebaf96e3bb","5ac8b7dae604410588d3908e6831349c","9a01745325e64a20b8d7afdbf842baeb","1f338b8388814cfdaa7fcbef5bfe9afe","af42eadb88af410b939b36cdeb2c5798","691ac3eaeb0e4a6ba6086eac18746640","f7ca5ff6fe3c4709bfc54b9d0b30f9b0","6967bcad3f3942b4aa683a30aa9335e3","3be9a73560e447b98d267134064aee73","0915c41cdd9c473f81083815c69d4621","e1712857ecdd457d812ea15093ac52e4","cede7be3be494db4a88f38f8e3cbbd1a","32fd0fede3554d82b118a34d7ba102bc","843b41830efc4740a03585dbd2f46d08","8664200eacb540a893522b73eb08efb8","cdd59cf9222d4bbbbbd66b3b3fa8f5c2","7c857ab6cd3547ca8a8e02f77b13bbcb","1507d4d8d84f4b58919a0a527dddc2ca","2af40aafb6e94b029a5794265ca4e6ad","92bc36549935417a817df97499f90e4c","393bf1308809482da56e4c47c9a02f7f","e724e404d3354f4ebc1f29cb28dfc25b","536f121fe07c412ba017a251e52da0b2","d42b801510d8430f89d47904cc7acd58","e2cd0fb66eea4f0a8179b4a0fccf1680","acc7dce9c87c4f87ad8efa575ef820e4","3c05158f17bf495b8edb5cafc8331ff9","486c950fe90d4035810220dd9c3539f4","35e52f32fc2248fe947ad4ee34709b8c","1e07453fd8df480a8efdd3550f914896","efbb454e48f94a3da8fab8ff80853eff","4b715e5b92fb4b99832361e750633c38","4b89de314fca4cad913ff3d896bf87a5","dbfb5c7191884f118d733c8c64d173ab","2256c9df37dc43ed973f3336cda89d48","f7e1b3ce26cd41d88a5b1d5ec3f712d4","7dd44bdda7724144955a984dda977f17","382ac7b5a6984f4cbf0402ca9d65d7ee","07a5dc636f3d49e4a559b1e04bcc3862","d5e94c3771f14948ad55ca0c05806bab","fcbc2c602fdc435db7bf2d44fd9eafd8","ef72c49a741349d8a438bf8ab6e5fb77","bd59975ac25046cea0768719f54def34","61ac5cb2f3d54794b0c0522ce86ed9f4","ef4a68cae2b24be7b0070e3c579e4de1","4a5a0f3936274477ae3d9396dedbc8ee","bfab32bf824c437fb37e909cd1f334f8","e3e5973a726840c68087247e4f7d6d34","0bb52dee28ec4437ae750a9f3e430392","18dadb8825ce49b3b5fa7da3c9251717","9de38d96b73447aa8e82186558ead4b0","9ac7f9557261454bab30654c3ac42e75","fc72ca2311444e81a3c0174b6c25d840","0771873723304418bb3e37e31ef822c2","504fd37c9881442d86379b4cbe80ecc7","f625ef8b52df48cba3a31fa2ddf040f6","49180a8c33d14b3eb2be27307ab65233","2172a6da1adc4353b10bbe97dc652a84","862e2e145f9c482ba79009a8e0c17bf1","5398361efc034b1599fa338575afbda8","63dd26b18adb4150808ea7c5564fcf55","04b23b294a0d47e481be8d6c13cb0452","b09e2dae23db413ca3043254f7dff292","9918ba9f61674ac684e3d576991fcdf5","7dc5b02f36304479b9e8c13848df3c7d","33d17bc2c89c4ae2aac8f068ff44421f","f55030cbc48645d6bdcc50e6796bf5bc","660ad2b7beca4084b048af5f3225bc1f","6fa53312a1a747ac89d8ef9ff5655a89","40b093a6e2674a348e70cb797e46e4af","98b29bc0c10f49a3845b0b7fbfa25fe4","ba76d45f15324a2c87dfc5a0781f2ad2","b37a8df63c784b9686ce75dfba20f11b","9baa05b728f84d26be3cd11081e9b4f1","76b99336d7654df48e9b6757fbf7a9ba","70a663d6153a432590a706d665c6c098","68adff24ec7f4fd59d9100c3d1313a65","c97a6ef027414c65ac665fe86d4a68d0","49881263dfbf430782d8b4ada8209fe2","07fb2241704d4605aba791e42973f656","9935324c5417467c89f02449fc924c3c","2536b674627943dc8c90a0bc5ce0a13c","0cbc8b1395d944ad95b4d732f5621bf8","9b70527ac3104a2ea150df8a501eefb4","4b32a38127b740f79fea3a9abc56282d","8e93bcf61b874226ba75ac166c2b5d84","0c114b71608d4b15a5ac635c80f13440","9859969992ab4a23aa4603977fecff7f","5078e7706cef42159cfe034a50f0af93","f95c6ebae9bd4423bdcfc908533f564b","7f86a0883c704145a6336b3215dc7222","b9158fc24d8a4519a1948416db9ea84f","f2752078a3d14dabae99dfc7bf0e3dcc","4f0a345d1ec04a4593777990ea134c5a","0b090400020e484eb6cc047cf2aa36db","69e43c11e49449fa8679e14f3972566f","8ded8735767140db9ffd760aca204307","409084e00c314649b0311c24a2e3eb35","eacfe6cc2a6c458c92ad5ef73c69d15f","73370adca3974457a68e15b07a0402d8","6bcd55dcea6b4a7b8f84ab572e99279a","ad33a616647c4824b8c2c77c92a4d53b","ea43b5060c234d6bb7f6ea73bf5d9f57","1966288965c847edbb79c6ea1e517178","b550b2e099f54ba9b87b1d92b447c0ba","0e1c1155323647fc85188532bcb2b076","4fd5ae96d94f4a4c945d05f7db010de2","ae4ff40c1a3145909d39521e4df397ce","120cf0fe31e1446cb2a9966f818d1e9e","963a68083a004228b0d16d05a4e7f3f4","fa321a6c32de4dbabfb2f3af2eae3eaa"]},"executionInfo":{"elapsed":14090,"status":"ok","timestamp":1686284671746,"user":{"displayName":"","userId":""},"user_tz":300},"id":"27TJGTZfavys","outputId":"59c2ec7d-52c6-4f68-e9be-4b5fa88a7618"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6128e9f3993544c0967b459aff338043","version_major":2,"version_minor":0},"text/plain":["Downloading (…)a8e1d/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"909daed29b91479cb960d637f6de31ed","version_major":2,"version_minor":0},"text/plain":["Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b13b0e0ef95847058b2ed145f5f1e5fc","version_major":2,"version_minor":0},"text/plain":["Downloading (…)b20bca8e1d/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d16a5b6a4a24d48a05853548067d191","version_major":2,"version_minor":0},"text/plain":["Downloading (…)0bca8e1d/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ac8b7dae604410588d3908e6831349c","version_major":2,"version_minor":0},"text/plain":["Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"32fd0fede3554d82b118a34d7ba102bc","version_major":2,"version_minor":0},"text/plain":["Downloading (…)e1d/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d42b801510d8430f89d47904cc7acd58","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2256c9df37dc43ed973f3336cda89d48","version_major":2,"version_minor":0},"text/plain":["Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4a5a0f3936274477ae3d9396dedbc8ee","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49180a8c33d14b3eb2be27307ab65233","version_major":2,"version_minor":0},"text/plain":["Downloading (…)a8e1d/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"660ad2b7beca4084b048af5f3225bc1f","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49881263dfbf430782d8b4ada8209fe2","version_major":2,"version_minor":0},"text/plain":["Downloading (…)8e1d/train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f95c6ebae9bd4423bdcfc908533f564b","version_major":2,"version_minor":0},"text/plain":["Downloading (…)b20bca8e1d/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6bcd55dcea6b4a7b8f84ab572e99279a","version_major":2,"version_minor":0},"text/plain":["Downloading (…)bca8e1d/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["example_encoding:\n"," [ 2.25026105e-02 -7.82917812e-02 -2.30307486e-02 -5.10006677e-03\n"," -8.03404450e-02  3.91321294e-02  1.13428580e-02  3.46483383e-03\n"," -2.94574704e-02 -1.88930072e-02  9.47434008e-02  2.92747878e-02\n","  3.94859761e-02 -4.63165939e-02  2.54246294e-02 -3.21999453e-02\n","  6.21928424e-02  1.55591788e-02 -4.67795618e-02  5.03902026e-02\n","  1.46113662e-02  2.31413934e-02  1.22066885e-02  2.50696652e-02\n","  2.93654157e-03 -4.19822149e-02 -4.01036721e-03 -2.27843709e-02\n"," -7.68588809e-03 -3.31090614e-02  3.22118513e-02 -2.09992286e-02\n","  1.16730649e-02 -9.85073894e-02  1.77932623e-06 -2.29931846e-02\n"," -1.31140910e-02 -2.80222818e-02 -6.99970722e-02  2.59314068e-02\n"," -2.89501362e-02  8.76336619e-02 -1.20919012e-02  3.98605317e-02\n"," -3.31382118e-02  3.59108336e-02  3.46099064e-02  6.49783984e-02\n"," -3.00817713e-02  6.98187873e-02 -3.99513636e-03 -1.01600029e-03\n"," -3.50185446e-02 -4.36567441e-02  5.08025587e-02  4.68757823e-02\n","  5.39663173e-02 -4.03008349e-02  3.20139038e-03  1.36618130e-02\n","  3.82188670e-02 -3.23845353e-03 -7.84586358e-04 -1.71188749e-02\n","  6.90439763e-03 -1.09237283e-02  8.63304827e-03 -1.82357989e-02\n","  1.87930949e-02  1.54990433e-02  1.02150096e-02 -2.48378026e-03\n","  1.03153428e-02  6.24887235e-02  3.60318157e-03 -6.26622839e-03\n"," -2.03405824e-02 -6.72353199e-03 -3.54771353e-02  3.43538225e-02\n","  6.72282279e-02  9.06873122e-02  1.32441204e-02  2.06592660e-02\n"," -2.78685652e-02  4.29694653e-02 -4.66859490e-02  1.50115648e-02\n"," -6.62284419e-02 -2.27593333e-02 -6.24990501e-02 -2.58455854e-02\n","  7.31309759e-04  1.14652757e-02  5.66383563e-02  2.06243643e-03\n"," -4.09248956e-02 -4.55051363e-02  1.66958347e-02 -8.31556916e-02\n","  2.09066248e-03 -8.70916713e-03  1.07622531e-04  3.37445401e-02\n","  5.60348202e-03 -1.66981556e-02  4.47909161e-02  6.31808676e-03\n"," -6.45904094e-02  5.29103652e-02  1.93019174e-02 -6.20153546e-03\n"," -1.18759967e-01  3.55963521e-02 -2.28864700e-02 -1.51872300e-02\n"," -5.92663838e-03 -1.57189439e-04  1.07069639e-02  3.86085082e-03\n"," -6.87015131e-02 -1.69752520e-02 -2.79730130e-02  2.80480720e-02\n","  2.47793999e-02  1.20279342e-02 -6.86393678e-02  4.92765270e-02\n","  1.87576562e-02 -2.42343470e-02 -2.05291603e-02 -1.07933935e-02\n","  2.46493109e-02 -3.33323255e-02 -3.28397714e-02  2.91978326e-02\n","  4.92032953e-02 -7.13365059e-03 -1.63389966e-02  1.78588438e-03\n","  2.18068287e-02 -8.90231207e-02 -3.37051526e-02  5.77225955e-03\n"," -4.56566028e-02  3.39890830e-02  3.52784172e-02 -3.12627852e-02\n","  8.10833368e-03  2.68614888e-02 -2.23898538e-03  2.81266645e-02\n"," -1.75383687e-02 -1.44589972e-02 -3.33480649e-02 -1.62954535e-02\n","  9.70038474e-02 -8.11068807e-03 -2.46668626e-02 -5.87456338e-02\n","  8.74859048e-04  1.67235136e-02  9.15385224e-03 -1.17982854e-03\n"," -2.93020299e-03  4.22467012e-03 -2.16529295e-02  4.29305658e-02\n"," -5.86095639e-02  3.13417837e-02 -1.29514618e-03 -1.11297900e-02\n"," -2.82019954e-02  8.77324268e-02  2.06880849e-02  1.41398599e-02\n","  1.38229392e-02 -1.94184072e-02 -9.01035592e-02 -3.81481717e-03\n"," -2.91159120e-03  3.09753716e-02 -1.18769128e-02  1.88289359e-02\n"," -4.59066592e-02  4.98210378e-02 -8.39177426e-03 -4.29713912e-02\n"," -3.23598869e-02 -3.83801050e-02 -2.99748089e-02  3.69881578e-02\n"," -4.44587693e-03 -1.94783807e-02 -2.71527953e-02  2.43246574e-02\n","  9.16432648e-04  5.85004650e-02  1.92714110e-02 -2.57291254e-02\n","  4.08677757e-02  4.36860975e-03  5.13519682e-02  1.57081001e-02\n"," -2.46329512e-02 -9.79607087e-03  2.06120592e-03 -4.66644503e-02\n","  3.19585130e-02 -3.73425782e-02  9.35152546e-02  1.85420625e-02\n"," -2.60215215e-02  8.05765949e-03 -6.38655110e-05 -4.74144192e-03\n","  2.17362121e-02 -4.03623767e-02 -3.97234857e-02  6.60505667e-02\n"," -3.20185497e-02 -1.52356476e-02 -1.53095610e-02  5.58152422e-03\n","  3.96784805e-02 -5.98881058e-02 -2.94910409e-02 -1.53479623e-02\n"," -3.32981646e-02 -1.35856112e-02 -2.23695319e-02  1.81127386e-03\n"," -2.53541162e-04  7.30925612e-03 -4.96328436e-02  3.74633968e-02\n"," -4.42487337e-02 -8.77881870e-02 -1.95525587e-02 -7.44620636e-02\n"," -5.28368633e-03 -8.59958772e-03  1.65657997e-02  1.99179146e-02\n"," -9.94190574e-03 -2.85211089e-03  7.21454173e-02 -1.99029427e-02\n","  2.95140687e-02 -5.97201101e-02  5.00880927e-02 -2.54911277e-02\n","  2.33916380e-02 -7.12675927e-03  7.38673843e-03 -7.17939511e-02\n","  9.14931181e-04  2.19873618e-02  4.15909849e-03  1.79544166e-02\n","  6.32213429e-02 -2.47941306e-03 -5.26579702e-03  2.34971251e-02\n"," -2.61955392e-02 -3.71229760e-02  2.15678625e-02 -5.85354753e-02\n"," -1.79577656e-02 -1.20005067e-02  8.96505371e-04 -1.47689646e-02\n","  4.96945046e-02  6.97954511e-03  2.64367871e-02  4.61773984e-02\n","  3.20433900e-02 -3.66005749e-02 -5.08421147e-03  6.88665509e-02\n","  5.68004549e-02 -1.46777891e-02 -4.78474945e-02  1.21871624e-02\n"," -2.50420682e-02  3.12442705e-02 -1.79439709e-02 -3.05826534e-02\n","  1.71711482e-03  7.02126697e-02  5.67383356e-02 -1.79368444e-02\n","  2.44000461e-02 -2.86525823e-02 -1.15867341e-02 -2.70408653e-02\n","  3.95130739e-02  4.29957323e-02  2.90972665e-02  2.80838665e-02\n"," -4.62749004e-02 -4.28294344e-03  1.19901923e-02 -1.20225055e-02\n"," -9.46940668e-03  2.35066321e-02 -3.00627723e-02 -1.69607922e-02\n"," -1.59735780e-03 -1.30610745e-02  5.35884537e-02  2.53782943e-02\n","  2.60250214e-02  6.27413169e-02 -2.26463489e-02  6.58663781e-03\n"," -3.48779149e-02 -8.88994616e-03 -3.32266763e-02 -1.81600042e-02\n"," -6.45450130e-03  1.02021480e-02 -1.25164455e-02  4.20163833e-02\n","  1.12152118e-02 -2.13345438e-02  1.05621023e-02  1.99820623e-02\n","  1.83803663e-02  3.29687330e-03 -8.70438199e-03  1.90762375e-02\n"," -4.41013798e-02  9.57715064e-02  2.73615494e-02  1.76533926e-02\n"," -2.20417902e-02  3.70631181e-02 -6.52673829e-04 -1.44511405e-02\n","  1.09791057e-02 -8.40490591e-03 -3.26196663e-03 -2.20720582e-02\n"," -1.90347321e-02 -1.60558317e-02 -4.08147462e-02  1.11608980e-02\n"," -6.02423064e-02 -6.96681440e-02 -1.73304286e-02  2.87935063e-02\n"," -6.79623261e-02 -3.13759185e-02 -5.51356189e-02 -2.03582626e-02\n","  2.89012939e-02  1.37794334e-02  6.80509256e-03 -2.43214075e-03\n","  7.21530691e-02 -1.17461092e-03 -3.57215330e-02  3.54786627e-02\n"," -1.96368992e-03 -7.76637578e-03  3.01939212e-02  1.85422022e-02\n"," -5.39994203e-02  3.32430005e-02  5.73030580e-03  1.33993253e-02\n","  4.51613218e-03  4.88920286e-02 -3.14347446e-02  3.62168700e-02\n","  3.65449227e-02 -4.79209833e-02 -1.44876121e-02  4.93125841e-02\n","  2.86978576e-02 -5.51462993e-02  2.74743754e-02  1.27805080e-02\n"," -7.04631954e-02  7.69067788e-03 -5.24687488e-03 -5.33922538e-02\n"," -1.70809068e-02  4.77676727e-02  2.38064751e-02 -4.09796834e-02\n"," -1.27406456e-02  4.66342606e-02  5.03483275e-03  6.60549244e-03\n","  2.90571749e-02  4.15973850e-02 -3.82126570e-02 -1.14388242e-02\n","  1.71640404e-02  5.70876896e-03  1.07285557e-02 -1.80592891e-02\n"," -5.06379642e-02  4.54925112e-02  1.40737975e-02  4.25583534e-02\n"," -3.22351381e-02  4.17672545e-02  1.14987167e-02  3.92396189e-03\n","  2.04459541e-02  1.52545655e-02  3.80402952e-02  2.54581142e-02\n"," -4.69273888e-03  1.83214862e-02  2.76016016e-02 -2.89157182e-02\n"," -4.98981029e-02 -1.61939599e-02  9.87022594e-02 -4.26361598e-02\n"," -1.88477784e-02 -1.07012223e-02 -3.21414992e-02  4.15321887e-02\n"," -2.38699317e-02  8.39931890e-03 -1.00904342e-03 -3.11340764e-02\n"," -3.86489555e-02 -3.06742564e-02 -3.88901010e-02 -3.65616418e-02\n","  3.29426234e-03  2.00938229e-02  2.30732132e-02 -4.77465726e-02\n","  8.55968427e-03  2.21940782e-02  1.49231181e-01 -1.91771667e-02\n","  1.43476771e-02  4.39949259e-02 -2.27761455e-03  1.38106837e-03\n","  3.23159546e-02  6.57535046e-02  2.26997174e-02  2.18100566e-02\n"," -3.00688799e-02  1.54186003e-02  6.95953593e-02 -3.88419256e-02\n"," -1.09261841e-01 -7.51075475e-03  1.19599300e-02  1.27546946e-02\n","  1.89590026e-02  4.54232544e-02 -4.60909568e-02 -5.17163519e-03\n"," -1.17528420e-02 -8.67661461e-03 -2.08859164e-02  4.49374653e-02\n","  1.55425165e-02  1.32864323e-02 -3.67461070e-02  1.40869608e-02\n","  2.77769612e-03  2.77871569e-03  2.99189389e-02 -3.01352236e-02\n"," -4.63992320e-02 -5.60871176e-02 -7.94625655e-03  3.58322971e-02\n"," -2.37628780e-02  3.04555744e-02  4.38166270e-03 -1.49128651e-02\n"," -2.00193264e-02  4.84519498e-03 -1.40724308e-03 -3.53151783e-02\n","  5.58816316e-03  7.45548820e-03  1.51486322e-03  4.03528959e-02\n"," -6.45007240e-03 -2.26507522e-03 -3.91197763e-02  1.05104009e-02\n","  1.14451451e-02  2.85172798e-02  2.43227556e-02 -8.16608518e-02\n"," -4.06114198e-02  4.48722541e-02  5.76137041e-04  3.66367325e-02\n"," -5.07901460e-02  3.42644639e-02  2.49840431e-02  1.17401816e-02\n","  1.71504728e-02  2.12810859e-02 -1.83074046e-02 -5.08700162e-02\n"," -1.79200135e-02  2.44995952e-02 -8.84231925e-03  1.70267001e-02\n"," -2.69820332e-03 -7.86308125e-02  5.88882305e-02  2.79413257e-03\n","  1.18669588e-02 -3.29489037e-02  2.49917451e-02 -3.39025483e-02\n"," -7.46754035e-02  2.85451533e-03 -4.59519448e-03  1.36553159e-03\n"," -6.91541284e-02  3.54953320e-03 -1.40170781e-02  6.54011965e-03\n"," -5.49735799e-02  4.28331271e-02 -5.33593819e-02  3.18162329e-03\n","  1.04328476e-01  3.42741832e-02  4.07343768e-02  1.89621169e-02\n","  2.44271345e-02 -1.29663236e-02  6.00200221e-02  3.92833129e-02\n","  7.58032501e-02 -1.51843037e-02 -7.98326451e-03  3.47589590e-02\n"," -1.86614431e-02 -6.96071684e-02 -7.13097826e-02  2.77238674e-02\n"," -3.20368260e-02  3.10048386e-02  1.26677367e-03 -6.69391282e-33\n"," -3.91474403e-02 -3.46212387e-02  2.06935778e-03  6.21102452e-02\n"," -4.16611731e-02 -9.90154594e-03 -1.67432912e-02  7.94497877e-03\n"," -1.07789366e-03  2.85014603e-02 -3.19683515e-02  1.79135089e-03\n","  3.13649923e-02 -1.40697183e-02  1.93634741e-02  7.51152541e-03\n","  3.52904573e-02 -1.16606001e-02 -2.80548539e-03 -1.19964583e-02\n"," -2.97140013e-02 -1.76579859e-02  4.52528372e-02 -1.38789078e-03\n"," -7.87150115e-03 -8.17415398e-03 -5.47759943e-02 -1.12036504e-02\n"," -6.26672581e-02 -2.15537511e-02  5.16278902e-03 -2.60673836e-02\n"," -1.97687224e-02 -2.41160616e-02 -3.39965038e-02  4.55973595e-02\n"," -5.38011733e-03 -5.15832677e-02  2.78135575e-02  3.86534072e-02\n"," -9.17188749e-02 -5.43298721e-02 -2.38128733e-02  8.47349130e-03\n"," -2.56151073e-02 -1.94259360e-02 -5.79075143e-03 -3.53576466e-02\n","  3.68123390e-02 -4.75911945e-02 -3.93513031e-02  1.03632116e-03\n"," -3.56920063e-02  4.05900814e-02 -3.41656338e-03  2.35696733e-02\n"," -1.65533759e-02 -1.51567149e-03 -4.22695316e-02  1.85887199e-02\n","  4.51937914e-02  5.00864275e-02 -3.62452343e-02 -3.38022299e-02\n"," -2.15227026e-02  7.74866203e-03  3.47937783e-03  8.42259964e-04\n","  1.18840542e-02  6.97644129e-02  8.02960619e-03  1.04670994e-01\n"," -4.34278287e-02  1.09933428e-01  2.27689110e-02 -3.14176716e-02\n"," -1.14897247e-02 -3.55337770e-03  2.82175746e-02 -1.62151773e-02\n","  6.32874072e-02  1.12804994e-02 -4.53989916e-02 -4.23893034e-02\n"," -4.77063954e-02 -4.93459851e-02 -3.72873875e-03  3.38707753e-02\n"," -3.09105664e-02  2.06780955e-02  3.08634639e-02  6.29141927e-02\n","  1.70472413e-02 -1.72119737e-02 -3.77116762e-02  3.45212556e-02\n"," -4.09610458e-02  4.88860020e-03 -3.00612859e-02 -8.41373205e-03\n"," -4.09953408e-02 -3.98016386e-02 -5.39269708e-02  1.65643226e-02\n","  5.96864633e-02  3.61519642e-02  4.98929434e-02  1.44996960e-02\n"," -1.09169647e-01 -1.43747777e-02 -1.36371404e-02  1.62526611e-02\n"," -1.17083022e-03 -3.09679247e-02 -2.90011670e-02 -6.66360091e-03\n","  9.04127210e-03  4.31807078e-02 -2.07463764e-02 -5.69087304e-02\n"," -2.79608257e-02  4.16314267e-02 -6.23094812e-02  2.17974558e-02\n","  2.10569706e-03  1.54057145e-02  3.57554592e-02  2.54537668e-02\n","  3.60637307e-02 -7.28387386e-02 -5.19865798e-03 -2.23384076e-03\n","  2.51205535e-07  4.48065810e-03  6.26780018e-02  2.36657560e-02\n","  6.45827726e-02  1.77587382e-02  4.13445123e-02 -3.67186777e-02\n","  5.56979366e-02 -4.12960202e-02  3.65489423e-02  7.52831250e-02\n"," -3.72790918e-02 -2.12006606e-02 -1.76452193e-02 -2.88425889e-02\n","  2.56824382e-02 -4.92919497e-02 -8.79911706e-02 -2.83660907e-02\n"," -2.19023824e-02  3.70794572e-02  4.11573872e-02  7.84277022e-02\n"," -1.48525024e-02  6.14955137e-03 -4.01153080e-02 -2.02855784e-02\n"," -2.90953107e-02  6.01130677e-03  3.68368812e-02  7.31773721e-03\n"," -8.81806388e-03  4.70298436e-03  3.01264301e-02 -3.82546335e-03\n"," -6.81492174e-03  3.72341909e-02  8.78986120e-02 -2.90224631e-03\n","  3.33461538e-02 -3.84543575e-02 -5.78215420e-02 -2.74080392e-02\n","  1.45640485e-02  1.58608146e-02  1.84694398e-02  3.52275856e-02\n"," -5.63630909e-02  2.07085405e-02  3.22306342e-02 -2.99263597e-02\n","  5.92910685e-02 -3.01268091e-03 -2.28289282e-03  2.80255172e-02\n"," -7.59407133e-02  4.06446075e-03  1.21565247e-02  1.28566260e-02\n"," -1.73889438e-03 -2.95145828e-02  3.77574824e-02  1.94634851e-02\n","  4.80340496e-02  1.52997011e-02  5.04777767e-02 -8.81988462e-03\n","  1.64886799e-34  4.77930494e-02 -6.48032781e-03 -3.31389811e-03\n","  1.02901114e-02 -3.30803841e-02 -2.55397577e-02  3.78654376e-02\n"," -1.35550592e-02 -8.27930029e-03  2.65268721e-02 -2.01899465e-03]\n"]}],"source":["# Initialize the pretrained transformer model\n","sentence_transformer_model = SentenceTransformer(\n","    'sentence-transformers/{model}'.format(model=SENTENCE_TRANSFORMER_MODEL))\n","\n","# Sanity check\n","example_encoding = sentence_transformer_model.encode(\n","    \"This is an example sentence\",\n","    normalize_embeddings=True\n",")\n","\n","print('example_encoding:\\n', example_encoding)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1686284671746,"user":{"displayName":"","userId":""},"user_tz":300},"id":"de0oQW1raJzY"},"outputs":[],"source":["class TransformerFeaturizer(BaseEstimator, TransformerMixin):\n","    def __init__(self, dim, sentence_transformer_model):\n","        self.dim = dim\n","        self.sentence_transformer_model = sentence_transformer_model\n","        # you can add any other params to be passed to the constructor here\n","\n","    #estimator. Since we don't have to learn anything in the featurizer, this is a no-op\n","    def fit(self, X, y=None):\n","        return self\n","\n","    #transformation: return the encoding of the document as returned by the transformer model \n","    def transform(self, X, y=None):\n","        X_t = []\n","        \"\"\"\n","        [TO BE IMPLEMENTED]\n","        \n","        Goal: TransformerFeaturizer's transform() method converts the raw text document\n","        into a feature vector to be passed as input to the classifier.\n","            \n","        Given below is a dummy implementation that always maps it to a zero vector.\n","        You have to implement this function so it uses computes a document embedding\n","        of the input document using self.sentence_transformer_model. \n","        This will be our feature representation of the document\n","        \"\"\"\n","        # for doc in X:\n","        #     # TODO: replace this dummy implementation\n","        #     X_t.append(np.zeros(self.dim))\n","        # return X_t\n","        return self.sentence_transformer_model.encode(X, normalize_embeddings=True, batch_size=128)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":198606,"status":"ok","timestamp":1686284876802,"user":{"displayName":"","userId":""},"user_tz":300},"id":"n1nwMri8aeFi","outputId":"56528ff0-1109-4023-d3e2-c1d0c71b8035"},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluating for training data size = 500\n","Accuracy on test set: 0.662\n","Evaluating for training data size = 1000\n","Accuracy on test set: 0.6774\n","Evaluating for training data size = 10000\n","Accuracy on test set: 0.7598\n","Evaluating for training data size = 25000\n","Accuracy on test set: 0.7716\n"]}],"source":["models_v2 = {}\n","for n in TRAIN_SIZE_EVALS:\n","    print(\"Evaluating for training data size = {}\".format(n))\n","    X_train_i = X_train[:n]\n","    Y_train_i = Y_train[:n]\n","\n","    \"\"\"\n","    [TO BE IMPLEMENTED]\n","        \n","    Goal: initialized below is a dummy sklearn Pipeline object with no steps.\n","    You have to replace it with a pipeline object which contains at least two steps:\n","    (1) mapping the input document to a feature vector (using TransformerFeaturizer)\n","    (2) a classifier that predicts the class label using the feature output of first step\n","\n","    You can add other steps to preproces, post-process your data as you see fit. \n","    You can also try any sklearn model architecture you want, but a linear classifier\n","    will do just fine to start with\n","\n","    e.g. \n","    pipeline = Pipeline([\n","        ('featurizer', <your TransformerFeaturizer class instance here>),\n","        ('classifier', <your sklearn classifier class instance here>)\n","    ])\n","    \"\"\"\n","    pipeline =  Pipeline([\n","        ('vect', TransformerFeaturizer(dim=1024, sentence_transformer_model=sentence_transformer_model)),\n","        ('clf', LogisticRegression(max_iter=1000, C=0.1))\n","    ])\n","\n","    # train\n","    pipeline.fit(X_train_i, Y_train_i)\n","    # predict\n","    Y_pred_i = pipeline.predict(X_test)\n","    # record results\n","    models_v2[n] = {\n","        'pipeline': pipeline,\n","        'test_predictions': Y_pred_i,\n","        'accuracy': accuracy_score(Y_true, Y_pred_i),\n","        'f1': f1_score(Y_true, Y_pred_i, average='weighted'),\n","        'errors': sum([x != y for (x, y) in zip(Y_true, Y_pred_i)])\n","    }\n","    print(\"Accuracy on test set: {}\".format(accuracy_score(Y_true, Y_pred_i)))\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xw89vQkE5woo"},"source":["## Step 5: [Modeling part 3] Large Language Models"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":472,"status":"ok","timestamp":1686284907028,"user":{"displayName":"","userId":""},"user_tz":300},"id":"jSijGuIc5yX4"},"outputs":[],"source":["# Here's a couple of code snippets to help you familiarize with how to generate labels with LLMs using langchain,\n","\n","from langchain.chat_models import ChatOpenAI\n","from langchain.schema import LLMResult, HumanMessage, Generation\n","\n","llm = ChatOpenAI(\n","    model_name=\"gpt-3.5-turbo\",\n","    # model_name='ada',\n","    max_tokens=1000,\n","    temperature=0.0,\n","    request_timeout=120,\n","    # It's better to do this an environment variable but putting it in plain text for clarity\n","    openai_api_key = OPEN_API_KEY\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":288},"executionInfo":{"elapsed":295,"status":"error","timestamp":1686284910836,"user":{"displayName":"","userId":""},"user_tz":300},"id":"NLzSZkJeY4Cs","outputId":"80b0135b-3dba-4e22-d3d1-6c5473b8b2a0"},"outputs":[{"ename":"ValidationError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-e5543a61fdb1>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mchat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatAnthropic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/main.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValidationError\u001b[0m: 1 validation error for ChatAnthropic\n__root__\n  Did not find anthropic_api_key, please add an environment variable `ANTHROPIC_API_KEY` which contains it, or pass  `anthropic_api_key` as a named parameter. (type=value_error)"]}],"source":["from langchain.chat_models import ChatAnthropic\n","from langchain.prompts.chat import (\n","    ChatPromptTemplate,\n","    SystemMessagePromptTemplate,\n","    AIMessagePromptTemplate,\n","    HumanMessagePromptTemplate,\n",")\n","from langchain.schema import (\n","    AIMessage,\n","    HumanMessage,\n","    SystemMessage\n",")\n","\n","chat = ChatAnthropic()\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":549,"status":"ok","timestamp":1686284916755,"user":{"displayName":"","userId":""},"user_tz":300},"id":"l5-u93SS50ip","outputId":"b2319a5d-5c6f-4a5b-847f-3dc84893d0db"},"outputs":[{"name":"stdout","output_type":"stream","text":["text='Positive' generation_info=None message=AIMessage(content='Positive', additional_kwargs={}, example=False)\n"]}],"source":["\n","zero_shot_prompt_template = \"\"\"\n","You are an expert at judging the sentiment of tweets. \n","Your job is to categorize the sentiment of a given tweet into one of three categories: Positive, Negative, Neutral.\n","\n","Tweet: {tweet}\n","Sentiment:\n","\"\"\"\n","\n","prompt = zero_shot_prompt_template.format(\n","    tweet=\"Yesss! I love machine learning\"\n",")\n","\n","result = llm.generate([[HumanMessage(content=prompt)]])\n","print(result.generations[0][0])\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":520,"status":"ok","timestamp":1686284918358,"user":{"displayName":"","userId":""},"user_tz":300},"id":"OovRQRuE52Tm","outputId":"ccb5917a-ab70-4730-96c3-06cec959ad42"},"outputs":[{"name":"stdout","output_type":"stream","text":["text='Positive' generation_info=None message=AIMessage(content='Positive', additional_kwargs={}, example=False)\n"]}],"source":["\n","few_shot_prompt_template = \"\"\"\n","You are an expert at judging the sentiment of tweets. \n","Your job is to categorize the sentiment of a given tweet into one of three categories: Positive, Negative, Neutral.\n","\n","Some example tweets along with the correct sentiment are shown below.\n","\n","Tweet: Another big happy 18th birthday to my partner in crime. I love u very much!\n","Sentiment: Positive\n","\n","Tweet: The more I use this application, the more I dislike it. It's slow and full of bugs.\n","Sentiment: Negative\n","\n","Tweet: #Dreamforce Returns to San Francisco for 20th Anniversary. Learn more: http://bit.ly/3AgwO0H\n","Sentiment: Neutral\n","\n","Now I want you to label the following example: \n","Tweet: {tweet}\n","Sentiment:\n","\"\"\"\n","\n","prompt = few_shot_prompt_template.format(\n","    tweet=\"I like chocolate\"\n",")\n","\n","result = llm.generate([[HumanMessage(content=prompt)]])\n","print(result.generations[0][0])\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"elapsed":295,"status":"ok","timestamp":1686284924149,"user":{"displayName":"","userId":""},"user_tz":300},"id":"_SHc75ThY4Cs","outputId":"fa70c76a-b0bd-4df6-efdd-44d4b4323c9f"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nYou are an expert at judging the sentiment of tweets. \\nYour job is to categorize the sentiment of a given tweet into one of three categories: Positive, Negative, Neutral.\\n\\nSome example tweets along with the correct sentiment are shown below.\\n\\nTweet: Another big happy 18th birthday to my partner in crime. I love u very much!\\nSentiment: Positive\\n\\nTweet: The more I use this application, the more I dislike it. It's slow and full of bugs.\\nSentiment: Negative\\n\\nTweet: #Dreamforce Returns to San Francisco for 20th Anniversary. Learn more: http://bit.ly/3AgwO0H\\nSentiment: Neutral\\n\\nNow I want you to label the following example: \\nTweet: I like chocolate\\nSentiment:\\n\""]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["prompt"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1686284925425,"user":{"displayName":"","userId":""},"user_tz":300},"id":"by3AxCi058qH"},"outputs":[],"source":["from sklearn.base import BaseEstimator, ClassifierMixin\n","\n","\n","class LLMClassifier(BaseEstimator, ClassifierMixin):\n","    def __init__(self, llm_model, prompt_template):\n","        self.llm_model = llm_model\n","        self.prompt_template = prompt_template\n","\n","    #This will be called during the training step\n","    def fit(self, X, y):\n","        return self\n","\n","    #This will be called during inference.\n","    def predict(self, X):\n","        \"\"\"\n","        [TO BE IMPLEMENTED]\n","        \n","        Goal: LLMClassifier's predict() method constructs the final prompt input\n","        for the LLM for each x in X, using the prompt template.\n","\n","        You have to implement this function so it does the following:\n","        1. Construct the final prompt for the LLM\n","        2. Call `self.llm_model` to generate the completion (label) for the prompt\n","        3. Do any post-processing/response parsing to fetch the label from the LLM response\n","        \"\"\"\n","        predictions = []\n","        for x in X:\n","            # Construct the final prompt for the LLM\n","            prompt = self.prompt_template.format(article = x)\n","\n","            # Call `self.llm_model` to generate the completion (label) for the prompt\n","            label = self.llm_model.generate([[HumanMessage(content=prompt)]]).generations[0][0].text\n","\n","            # Do any post-processing/response parsing to fetch the label from the LLM response\n","            predictions.append(label)\n","\n","        return predictions\n","        # pass\n"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1686284927896,"user":{"displayName":"","userId":""},"user_tz":300},"id":"vNykM9_eY4Cs"},"outputs":[],"source":["news_category_zero_shot_template = \"\"\"\n","You are an expert at categorizing the topics of different articles. \n","Your job is to receive information about a news article, including title and summary and categorize the topic\n","The possible topic categories are: 'Business', 'Sci/Tech', 'Software and Developement', 'Entertainment', 'Sports', 'Health', 'Toons' and 'Music Feeds'.\n","\n","I want you to label the following example: \n","Article information: {article}\n","Category:\n","\"\"\""]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":182,"status":"ok","timestamp":1686287606326,"user":{"displayName":"","userId":""},"user_tz":300},"id":"PKPOQcJWY4Ct"},"outputs":[],"source":["X_train_i = X_train[:5000]\n","Y_train_i = Y_train[:5000]"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":710054,"status":"ok","timestamp":1686288318061,"user":{"displayName":"","userId":""},"user_tz":300},"id":"CVemE-2R5-xN","outputId":"23552834-6371-4acb-b39c-2b4368f69ba3"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1c0c6c0592f2d454a7489eb4d587647a in your message.).\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89059 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88903 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89004 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89085 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89197 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89074 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89175 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88985 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88983 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89431 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88950 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89121 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89179 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89051 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89189 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89132 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88967 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89008 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88925 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89005 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89276 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89310 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88860 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89413 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88939 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89048 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89025 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89094 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88946 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89103 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89037 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89176 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89028 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89317 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89284 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89205 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88798 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88979 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89092 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88882 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89222 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89149 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88948 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89032 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1f4565a844164074303c9bd97fe22c88 in your message.).\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88977 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88896 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89143 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89135 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89116 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89138 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89140 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88864 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89183 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89009 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88936 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89401 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88961 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89439 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89310 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89061 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89126 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89172 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88978 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88884 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88984 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89325 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89278 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89107 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2ecfd21cb7cc17bbc1ed29c4d1d95840 in your message.).\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89281 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89210 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88955 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89367 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89301 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89287 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89249 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89237 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89055 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89046 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89336 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89227 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89245 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89068 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88968 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88922 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89240 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89056 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88863 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89052 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88872 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88929 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89307 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89086 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89248 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88902 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89110 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88994 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88904 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89103 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89307 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89150 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89292 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88885 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89034 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89139 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89296 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89370 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89337 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88938 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89354 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89123 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88958 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89397 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89061 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88951 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88921 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89077 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89163 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89148 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89026 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89182 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88888 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88979 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89451 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89105 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89026 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88895 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89057 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88982 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy on test set: 0.649\n"]}],"source":["# Zero-shot classification pipeline with LLMs\n","\n","models_v3 = {}\n","\n","\"\"\"\n","[TO BE IMPLEMENTED]\n","        \n","Goal: initialized below is a dummy sklearn Pipeline object with no steps.\n","You have to replace it with a pipeline object which uses the `LLMClassifier` you have implemented \n","above to perform zero-shot classification on the test set.\n","\n","You can add other steps to preproces, post-process your data as you see fit. \n","\n","\"\"\"\n","pipeline = Pipeline([('LLMClassifier', LLMClassifier(llm, news_category_zero_shot_template))])\n","\n","# train\n","pipeline.fit(X_train_i, Y_train_i)\n","# predict\n","Y_pred_i = pipeline.predict(X_test)\n","# record results\n","models_v3[\"zero-shot\"] = {\n","    'test_predictions': Y_pred_i,\n","    'accuracy': accuracy_score(Y_true, Y_pred_i),\n","    'f1': f1_score(Y_true, Y_pred_i, average='weighted'),\n","    'errors': sum([x != y for (x, y) in zip(Y_true, Y_pred_i)])\n","}\n","print(\"Accuracy on test set: {}\".format(accuracy_score(Y_true, Y_pred_i)))"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":269,"status":"ok","timestamp":1686288620664,"user":{"displayName":"","userId":""},"user_tz":300},"id":"ADv2RkwDY4Ct"},"outputs":[],"source":["news_category_few_shot_template = \"\"\"\n","You are an expert at categorizing the topics of different articles. \n","You receive info about a news article and have to categorize the topic.\n","The possible topic categories are: 'Business', 'Sci/Tech', 'Software and Developement', 'Entertainment', 'Sports', 'Health', 'Toons' and 'Music Feeds'.\n","\n","Some examples below.\n","\n","Article information: EU to Rule Tuesday on Oracle's Bid for PeopleSoft. European Union regulators will decide Tuesday whether Oracle Corporation hostile $7.7 billion bid for rival business software concern PeopleSoft Inc. can proceed, the EU's antitrust chief said Friday.\n","Category: Sci/Tech\n","\n","Article information: Capsule from Genesis Space Probe Crashes in Utah Desert. A capsule carrying solar material from the Genesis space probe has made a crash landing at a US Air Force training facility in the US state of Utah.\n","Category: Entertainment\n","\n","\n","I want you to label the following example: \n","Article information: {article}\n","Category:\n","\"\"\""]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":797419,"status":"ok","timestamp":1686289418705,"user":{"displayName":"","userId":""},"user_tz":300},"id":"PvCbruqf6ASV","outputId":"dfa4d097-e5cf-48d8-a166-69eb6666d09c"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89050 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89268 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88788 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89050 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88936 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89375 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89040 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89133 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88819 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89011 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89118 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88938 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89242 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88722 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88986 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89197 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88826 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88862 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89511 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88971 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88736 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88921 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89105 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89235 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89432 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89285 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89035 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89423 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88941 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89135 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88744 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88797 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88740 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88807 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89060 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88746 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88879 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89132 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89129 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88784 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88925 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88995 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89018 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89142 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89041 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88824 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89437 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89070 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89086 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88838 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4ab6834c06c599cb42a64f9bf29e888c in your message.).\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88798 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89109 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89319 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88956 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88894 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88973 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88963 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88868 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88968 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89192 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88898 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89281 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88813 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89073 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88969 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89255 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88900 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88749 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89086 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89212 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88906 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89080 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89346 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89081 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89129 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89394 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88814 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88902 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89216 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88840 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88998 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89273 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88873 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89181 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88804 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88888 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89413 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89191 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88911 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89184 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89458 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88894 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89080 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88961 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89068 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88998 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89407 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89135 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89396 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89153 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88837 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88907 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89204 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89017 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88849 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88973 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89018 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89293 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88949 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89022 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89423 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88980 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89311 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88771 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89304 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88955 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89074 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88726 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88802 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89189 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89058 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88934 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89180 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89102 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88792 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89123 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89233 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89111 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89375 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89000 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89254 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88861 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 266db477de2be00cd32e07382b7edc6f in your message.).\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89259 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88955 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89038 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88740 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89093 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89283 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88878 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89045 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89324 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88987 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89454 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88967 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89129 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88901 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89215 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89241 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88846 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88831 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89152 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88826 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89184 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88906 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89286 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88898 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89156 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88847 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89088 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88893 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89405 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89153 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88763 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89254 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89045 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88887 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89108 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88988 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88982 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88807 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89002 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89181 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89251 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88767 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89429 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89191 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88951 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89235 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88750 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88890 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89187 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88824 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88993 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89380 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89236 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89433 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89279 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89229 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88726 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88852 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89191 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89211 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89188 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89308 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88956 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89016 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89238 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88859 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89321 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88729 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88979 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89130 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89201 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89251 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89042 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88810 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89176 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88873 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89226 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88943 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89216 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88853 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89353 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89022 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89453 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88788 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89038 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88848 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89140 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88817 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88823 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89192 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88745 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89180 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89052 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88850 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88832 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89180 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89031 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89036 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89409 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89011 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89336 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88952 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89080 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88917 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89414 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89101 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88714 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88810 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89044 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88884 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89149 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 89416 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88912 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88889 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n","WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-by3c5EoEWOFu8Vs6cwbhspzH on tokens per min. Limit: 90000 / min. Current: 88960 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy on test set: 0.61\n"]}],"source":["# Few-shot classification with LLMs\n","\n","\"\"\"\n","[TO BE IMPLEMENTED]\n","        \n","Goal: initialized below is a dummy sklearn Pipeline object with no steps.\n","You have to replace it with a pipeline object which uses the `LLMClassifier` you have implemented \n","above to perform few-shot classification on the test set.\n","\n","With few-shot classification, you can pass upto 5 demonstration examples as part of the prompt \n","to the LLM. You can add other steps to preproces, post-process your data as you see fit. \n","\n","\"\"\"\n","pipeline = Pipeline([('LLMClassifier', LLMClassifier(llm, news_category_few_shot_template))])\n","\n","# train\n","pipeline.fit(X_train_i, Y_train_i)\n","# predict\n","Y_pred_i = pipeline.predict(X_test)\n","# record results\n","models_v3[\"few-shot\"] = {\n","    'test_predictions': Y_pred_i,\n","    'accuracy': accuracy_score(Y_true, Y_pred_i),\n","    'f1': f1_score(Y_true, Y_pred_i, average='weighted'),\n","    'errors': sum([x != y for (x, y) in zip(Y_true, Y_pred_i)])\n","}\n","print(\"Accuracy on test set: {}\".format(accuracy_score(Y_true, Y_pred_i)))\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qdQDQ8Sla2u3"},"source":["## Step 5: Report Results from previous two steps"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E9cPbEv_Y4Ct","outputId":"77f7a4b0-5c78-4384-e7ed-f204d2919300"},"outputs":[{"data":{"text/plain":["dict_items([(500, {'pipeline': Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n","                ('clf', LogisticRegression(C=0.1, max_iter=1000))]), 'test_predictions': array(['Business', 'Entertainment', 'Entertainment', ..., 'Sports',\n","       'Entertainment', 'Business'], dtype='<U25'), 'accuracy': 0.3434, 'f1': 0.23815090506518286, 'errors': 3283}), (1000, {'pipeline': Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n","                ('clf', LogisticRegression(C=0.1, max_iter=1000))]), 'test_predictions': array(['Business', 'Entertainment', 'Sports', ..., 'Sports',\n","       'Entertainment', 'Business'], dtype='<U25'), 'accuracy': 0.491, 'f1': 0.42194390708266594, 'errors': 2545}), (10000, {'pipeline': Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n","                ('clf', LogisticRegression(C=0.1, max_iter=1000))]), 'test_predictions': array(['Business', 'Entertainment', 'Sports', ..., 'Sports',\n","       'Entertainment', 'Business'], dtype='<U25'), 'accuracy': 0.6474, 'f1': 0.619593901371379, 'errors': 1763}), (25000, {'pipeline': Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n","                ('clf', LogisticRegression(C=0.1, max_iter=1000))]), 'test_predictions': array(['Business', 'Entertainment', 'Sports', ..., 'Sports', 'Health',\n","       'Business'], dtype='<U25'), 'accuracy': 0.7016, 'f1': 0.6909593714049721, 'errors': 1492})])"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["models.items()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IpKaurcHa0Vh","outputId":"ff288f16-c788-438e-b113-8a31a8ea1f98"},"outputs":[{"name":"stdout","output_type":"stream","text":["N-gram Models: \n","Train size: 500  |  Accuracy: 0.3434  |  F1 score: 0.23815090506518286 |  Num errors: 3283\n","Train size: 1000  |  Accuracy: 0.491  |  F1 score: 0.42194390708266594 |  Num errors: 2545\n","Train size: 10000  |  Accuracy: 0.6474  |  F1 score: 0.619593901371379 |  Num errors: 1763\n","Train size: 25000  |  Accuracy: 0.7016  |  F1 score: 0.6909593714049721 |  Num errors: 1492\n"]}],"source":["# Report results\n","\n","print(\"N-gram Models: \")\n","for train_size, result in models.items():\n","    print(\"Train size: {0}  |  Accuracy: {1}  |  F1 score: {2} |  Num errors: {3}\".format(\n","        train_size,\n","        result['accuracy'],\n","        result['f1'],\n","        result['errors']\n","    ))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rztr78oD6EQp","outputId":"5a9f0fae-45dc-424e-bcfb-6657e7ff900a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Pretrained Transformer Models: \n","Train size: 500  |  Accuracy: 0.662  |  F1 score: 0.6227476339069221 |  Num errors: 1690\n","Train size: 1000  |  Accuracy: 0.6774  |  F1 score: 0.6389611475382116 |  Num errors: 1613\n","Train size: 10000  |  Accuracy: 0.7598  |  F1 score: 0.7514273185090816 |  Num errors: 1201\n","Train size: 25000  |  Accuracy: 0.7716  |  F1 score: 0.7632906461344938 |  Num errors: 1142\n"]}],"source":["print(\"Pretrained Transformer Models: \")\n","for train_size, result in models_v2.items():\n","    print(\"Train size: {0}  |  Accuracy: {1}  |  F1 score: {2} |  Num errors: {3}\".format(\n","        train_size,\n","        result['accuracy'],\n","        result['f1'],\n","        result['errors']\n","    ))"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1686289418705,"user":{"displayName":"","userId":""},"user_tz":300},"id":"b_sQOJW36Cqr","outputId":"f342faf6-293a-4069-c417-2d30ded483d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Large Language Models: \n","Mode: zero-shot  |  Accuracy: 0.649  |  F1 score: 0.6540181621675356 |  Num errors: 351\n","Mode: few-shot  |  Accuracy: 0.61  |  F1 score: 0.604614279652834 |  Num errors: 390\n"]}],"source":["print(\"Large Language Models: \")\n","for mode, result in models_v3.items():\n","    print(\"Mode: {0}  |  Accuracy: {1}  |  F1 score: {2} |  Num errors: {3}\".format(\n","        mode,\n","        result['accuracy'],\n","        result['f1'],\n","        result['errors']\n","    ))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4v882hLIa6gR"},"source":["## Step 6: Data Augmentation [Optional]\n","\n","In this section, we want to explore how to augment data efficiently to your existing training data. This is a very empirical exercise with a less well-defined playbook which means this section of the project is going to be open ended. Let us first understand what we mean by efficiency here, and why it matters:\n","\n","### Performance Gain (G):\n","We will measure performance gain from data augmentation as the improvement in model accuracy (reduction in num. errors) on the Test dataset as defined above. \n","\n","### Budget (K):\n","We will measure \"budget\" as the number of additional rows augmentated to the original training dataset.  In this project, the universe of data from which you will select to add to your training set is Datasets['augment'] (and downstream X_augment, Y_augment).\n","\n","This data is already labeled of course, but in most real-world scenarios the additional data is typically unlabeled. In order to augment it to your training data, you have to get it annotated which incurs some cost in time & money. This is the motivation to consider budget as a metric.\n","\n","### Efficiency (E = G / K): \n","Efficiency = Performance Gain (Reduction in num errors in test set) / Budget (Number of additional rows augmented to the training dataset)\n","\n","We want to get the maximum gain in performance, while incurring minimum annotation cost."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"-a-kk3Pk6Jx-"},"source":["\n","\n","We can always sample more data at random from the augmentation set, and this is probably the first thing to try. Can we be more intelligent with the data we choose to augment to the training dataset?\n","\n","**Idea 1**: Look at the test errors that the current model is making. How can this help us guide our \"data collection\" for augmentation? One possible idea is to select examples from the augmentation dataset that are similar to these errors and add them to the training data. Similarity can be approximated in many ways:\n","1. [Jaccard distance between two texts](https://studymachinelearning.com/jaccard-similarity-text-similarity-metric-in-nlp/)\n","2. L2 distance between mean word vectors (we already compute these features for the entire dataset using WordVectorFeaturizer)\n","3. L2 distance between sentence transformer embedding (we already compute these features for the entire dataset using TransformerFeaturizer)\n","  \n","\n","**Idea 2**: Compute model's predictions on the augmentation dataset, and include those examples to the training dataset that the model finds \"hard\" ? (a proxy for this would be to look at cases where the output score distribution across all labels has nearly identical scores for top two or three labels).\n","\n","**Idea 3**: Look at the test errors that the current model is making, and the distribution of these errors across labels. Select examples from the augmentation dataset that belong to these classes - adding more training data for labels that the curent model does not do well on, can improve performance (assuming label quality is good)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":607,"status":"ok","timestamp":1686286942132,"user":{"displayName":"","userId":""},"user_tz":300},"id":"4UVN6r0abKHI","outputId":"49c16909-5a4f-44f1-dbd3-60ca1425f6a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of errors in the test set: 1492\n","Example errors: [example, true label, predicted label]\n","(\"European Union regulators will decide Tuesday whether Oracle Corp.'s hostile \\\\$7.7 billion bid for rival business software concern PeopleSoft Inc. can proceed, the EU's antitrust chief said Friday.\", 'Sci/Tech', 'Business')\n","('Rejecting the national pharmacare plan favoured by the provinces, federal health minister Ujjal Dosanjh says he #39;s confident a strategy is still in the works.', 'Health', 'Entertainment')\n","('', 'Business', 'Entertainment')\n","('Police said Wednesday a woman who lives at the home found the intruder Sept. 27 and called police. A police dog tried to track the intruder but the person got away.', 'Sports', 'Entertainment')\n","('The Samsung device has at least twice the density of any graphics memory available today, offering gamers much richer textures and imagery, the electronics giant said.', 'Sci/Tech', 'Entertainment')\n","('OCTOBER 22, 2004 (IDG NEWS SERVICE) - Yahoo Inc. has snapped up privately held software company Stata Labs, which develops technology allowing users to quickly search through e-mail and attachments.', 'Entertainment', 'Sci/Tech')\n","('The unexpected windfall from DVD sales have become the wild card in Hollywoods negotiations with the Screen Actors Guild.', 'Business', 'Entertainment')\n","('Within the next 18 months more than 20 million mobile telephone users in Britain, Germany and Ireland will finally gain access to a high-speed internet service which has revolutionised mobile communications for tens of millions of Japanese since its', 'Entertainment', 'Sci/Tech')\n","('European Ryder Cup captain Bernhard Langer named Britons Colin Montgomerie and Luke Donald as his wildcard picks on Sunday for next month #39;s match against the United States.', 'Entertainment', 'Sports')\n","('ATA, the biggest airline at Chicago #39;s Midway Airport, filed for bankruptcy protection Tuesday and said it will unload its Midway hub to AirTran Airways.', 'Entertainment', 'Business')\n"]}],"source":["# Examine current test errors\n","test_errors = []\n","Y_pred_i = models[25000]['test_predictions']\n","\n","for idx, label in enumerate(Y_true):\n","    if label != Y_pred_i[idx]:\n","        test_errors.append((X_test[idx], label,  Y_pred_i[idx]))\n","\n","print(\"Number of errors in the test set: {}\".format(len(test_errors)))\n","print(\"Example errors: [example, true label, predicted label]\")\n","for i in range(10):\n","    print(test_errors[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X2LCwb4ibYsV"},"outputs":[],"source":["'''\n","[TO BE IMPLEMENTED]\n","\n","Your additional data augmentation explorations go here\n","\n","For instance, the pseudocode for Idea (1) might look like the following:\n","\n","Augmented = {}\n","For e in test_errors:\n","   1. X_nn, y_nn = k nearest neighbors to (e) from X_augment, y_augment\n","   2. Add each (x, y) from (X_nn, y_nn) to Augmented\n","\n","Add the Augmented examples to the training set\n","Train the new model and record performance improvements\n","\n","'''"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://github.com/srujanreddyj/mlops-project/blob/main/%5BMLOps%5D%5BJune_2023%5D_Week_1_starter.ipynb","timestamp":1686290300633}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0384383090b540b49b87c0662e11ae27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a38d9789009c4eb9af2ab6eb1c084675","placeholder":"​","style":"IPY_MODEL_3c19dcdee0a24611b4f6373f6bda11d4","value":"Downloading (…)a8e1d/.gitattributes: 100%"}},"04b23b294a0d47e481be8d6c13cb0452":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0771873723304418bb3e37e31ef822c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"07a5dc636f3d49e4a559b1e04bcc3862":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07fb2241704d4605aba791e42973f656":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b70527ac3104a2ea150df8a501eefb4","placeholder":"​","style":"IPY_MODEL_4b32a38127b740f79fea3a9abc56282d","value":"Downloading (…)8e1d/train_script.py: 100%"}},"083391f721584cc89829bc9065d18119":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_294508e886d747269b8dd1871746eb62","placeholder":"​","style":"IPY_MODEL_4e8c0b86106a44f58f079200e8b1bdcf","value":" 190/190 [00:00&lt;00:00, 9.11kB/s]"}},"0915c41cdd9c473f81083815c69d4621":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0b090400020e484eb6cc047cf2aa36db":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bb52dee28ec4437ae750a9f3e430392":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_504fd37c9881442d86379b4cbe80ecc7","placeholder":"​","style":"IPY_MODEL_f625ef8b52df48cba3a31fa2ddf040f6","value":" 239/239 [00:00&lt;00:00, 13.6kB/s]"}},"0c114b71608d4b15a5ac635c80f13440":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0cbc8b1395d944ad95b4d732f5621bf8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cde3b3731e548209330c4ed68c3ebbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa6062fde486403eb74a93c36c76d7a9","max":571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_16a91b33e5d74539884a571d8883eb17","value":571}},"0e1c1155323647fc85188532bcb2b076":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11038e9233654ca381788e372596ea06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f69bbf81d524cd1858b429cfdcf90f7","placeholder":"​","style":"IPY_MODEL_cd97c277505f433e9aae1c35e9fbc881","value":" 10.6k/10.6k [00:00&lt;00:00, 669kB/s]"}},"120cf0fe31e1446cb2a9966f818d1e9e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"12f2ca96d9124b559b325544335243a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1507d4d8d84f4b58919a0a527dddc2ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16a91b33e5d74539884a571d8883eb17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"18dadb8825ce49b3b5fa7da3c9251717":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1966288965c847edbb79c6ea1e517178":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_963a68083a004228b0d16d05a4e7f3f4","placeholder":"​","style":"IPY_MODEL_fa321a6c32de4dbabfb2f3af2eae3eaa","value":" 349/349 [00:00&lt;00:00, 27.6kB/s]"}},"1ba315543b134766bfd54c14e96170b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cb4d447392b470fb1133a6695bc1327":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1f99a3aa74d4802b969362dfefdbe0f","max":10571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d9dab577cb8b4a4088bff883dc410a8f","value":10571}},"1e07453fd8df480a8efdd3550f914896":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f338b8388814cfdaa7fcbef5bfe9afe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3be9a73560e447b98d267134064aee73","max":116,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0915c41cdd9c473f81083815c69d4621","value":116}},"2172a6da1adc4353b10bbe97dc652a84":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04b23b294a0d47e481be8d6c13cb0452","placeholder":"​","style":"IPY_MODEL_b09e2dae23db413ca3043254f7dff292","value":"Downloading (…)a8e1d/tokenizer.json: 100%"}},"2256c9df37dc43ed973f3336cda89d48":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f7e1b3ce26cd41d88a5b1d5ec3f712d4","IPY_MODEL_7dd44bdda7724144955a984dda977f17","IPY_MODEL_382ac7b5a6984f4cbf0402ca9d65d7ee"],"layout":"IPY_MODEL_07a5dc636f3d49e4a559b1e04bcc3862"}},"2481382d29194555b3c07490e4b7c6c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2536b674627943dc8c90a0bc5ce0a13c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9859969992ab4a23aa4603977fecff7f","placeholder":"​","style":"IPY_MODEL_5078e7706cef42159cfe034a50f0af93","value":" 13.1k/13.1k [00:00&lt;00:00, 900kB/s]"}},"2805b644dcce45d8941ef373be17b3ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"294508e886d747269b8dd1871746eb62":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2af40aafb6e94b029a5794265ca4e6ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2cb7e553870d4f1fbf10d281fb0204fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a57b192eeec46f3b304a63294df723a","placeholder":"​","style":"IPY_MODEL_f654477856014076b6f39c985d227c88","value":" 1.18k/1.18k [00:00&lt;00:00, 49.4kB/s]"}},"30206105d1dd44a08a7f273df91dcb58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1545436a1b24e7dbb8a7649f043f51d","max":1175,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ea9550f524124539be002af02a679256","value":1175}},"32fd0fede3554d82b118a34d7ba102bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_843b41830efc4740a03585dbd2f46d08","IPY_MODEL_8664200eacb540a893522b73eb08efb8","IPY_MODEL_cdd59cf9222d4bbbbbd66b3b3fa8f5c2"],"layout":"IPY_MODEL_7c857ab6cd3547ca8a8e02f77b13bbcb"}},"33d17bc2c89c4ae2aac8f068ff44421f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35e52f32fc2248fe947ad4ee34709b8c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"382ac7b5a6984f4cbf0402ca9d65d7ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61ac5cb2f3d54794b0c0522ce86ed9f4","placeholder":"​","style":"IPY_MODEL_ef4a68cae2b24be7b0070e3c579e4de1","value":" 53.0/53.0 [00:00&lt;00:00, 3.35kB/s]"}},"393bf1308809482da56e4c47c9a02f7f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3be9a73560e447b98d267134064aee73":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c05158f17bf495b8edb5cafc8331ff9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b89de314fca4cad913ff3d896bf87a5","placeholder":"​","style":"IPY_MODEL_dbfb5c7191884f118d733c8c64d173ab","value":" 438M/438M [00:01&lt;00:00, 286MB/s]"}},"3c19dcdee0a24611b4f6373f6bda11d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"409084e00c314649b0311c24a2e3eb35":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"40b093a6e2674a348e70cb797e46e4af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_76b99336d7654df48e9b6757fbf7a9ba","max":363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_70a663d6153a432590a706d665c6c098","value":363}},"43859ef9bdb04f938e21d5d347b78e6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cde5ee78d574b0a9014df9b56088f02","placeholder":"​","style":"IPY_MODEL_12f2ca96d9124b559b325544335243a2","value":"Downloading (…)b20bca8e1d/README.md: 100%"}},"486c950fe90d4035810220dd9c3539f4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49180a8c33d14b3eb2be27307ab65233":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2172a6da1adc4353b10bbe97dc652a84","IPY_MODEL_862e2e145f9c482ba79009a8e0c17bf1","IPY_MODEL_5398361efc034b1599fa338575afbda8"],"layout":"IPY_MODEL_63dd26b18adb4150808ea7c5564fcf55"}},"49881263dfbf430782d8b4ada8209fe2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_07fb2241704d4605aba791e42973f656","IPY_MODEL_9935324c5417467c89f02449fc924c3c","IPY_MODEL_2536b674627943dc8c90a0bc5ce0a13c"],"layout":"IPY_MODEL_0cbc8b1395d944ad95b4d732f5621bf8"}},"4a5a0f3936274477ae3d9396dedbc8ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bfab32bf824c437fb37e909cd1f334f8","IPY_MODEL_e3e5973a726840c68087247e4f7d6d34","IPY_MODEL_0bb52dee28ec4437ae750a9f3e430392"],"layout":"IPY_MODEL_18dadb8825ce49b3b5fa7da3c9251717"}},"4b32a38127b740f79fea3a9abc56282d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b715e5b92fb4b99832361e750633c38":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4b89de314fca4cad913ff3d896bf87a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e8c0b86106a44f58f079200e8b1bdcf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f0a345d1ec04a4593777990ea134c5a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f984c50813a4c6c9f8f7b5f4debf52d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4fd5ae96d94f4a4c945d05f7db010de2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"504fd37c9881442d86379b4cbe80ecc7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5078e7706cef42159cfe034a50f0af93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"536f121fe07c412ba017a251e52da0b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5398361efc034b1599fa338575afbda8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33d17bc2c89c4ae2aac8f068ff44421f","placeholder":"​","style":"IPY_MODEL_f55030cbc48645d6bdcc50e6796bf5bc","value":" 466k/466k [00:00&lt;00:00, 2.79MB/s]"}},"548bb2407766465eacc5e211fc740ea6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ac8b7dae604410588d3908e6831349c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a01745325e64a20b8d7afdbf842baeb","IPY_MODEL_1f338b8388814cfdaa7fcbef5bfe9afe","IPY_MODEL_af42eadb88af410b939b36cdeb2c5798"],"layout":"IPY_MODEL_691ac3eaeb0e4a6ba6086eac18746640"}},"602eb03787b1446eade6e083ec913f60":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_548bb2407766465eacc5e211fc740ea6","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aac62ff40b7742bda6cc627eec331b34","value":190}},"6070cfde65124e9e908219044e2abd43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb3ba136cdc2465c8e058725fe920f2b","placeholder":"​","style":"IPY_MODEL_6c7c752986d64c559d29e6a53143f232","value":"Downloading (…)_Pooling/config.json: 100%"}},"6128e9f3993544c0967b459aff338043":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0384383090b540b49b87c0662e11ae27","IPY_MODEL_30206105d1dd44a08a7f273df91dcb58","IPY_MODEL_2cb7e553870d4f1fbf10d281fb0204fe"],"layout":"IPY_MODEL_2481382d29194555b3c07490e4b7c6c3"}},"61ac5cb2f3d54794b0c0522ce86ed9f4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63dd26b18adb4150808ea7c5564fcf55":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"660ad2b7beca4084b048af5f3225bc1f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6fa53312a1a747ac89d8ef9ff5655a89","IPY_MODEL_40b093a6e2674a348e70cb797e46e4af","IPY_MODEL_98b29bc0c10f49a3845b0b7fbfa25fe4"],"layout":"IPY_MODEL_ba76d45f15324a2c87dfc5a0781f2ad2"}},"68adff24ec7f4fd59d9100c3d1313a65":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"691ac3eaeb0e4a6ba6086eac18746640":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6967bcad3f3942b4aa683a30aa9335e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69e43c11e49449fa8679e14f3972566f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a57b192eeec46f3b304a63294df723a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bcd55dcea6b4a7b8f84ab572e99279a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ad33a616647c4824b8c2c77c92a4d53b","IPY_MODEL_ea43b5060c234d6bb7f6ea73bf5d9f57","IPY_MODEL_1966288965c847edbb79c6ea1e517178"],"layout":"IPY_MODEL_b550b2e099f54ba9b87b1d92b447c0ba"}},"6c7c752986d64c559d29e6a53143f232":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d16a5b6a4a24d48a05853548067d191":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8aeadeebe25a417fa8159a453eae90ab","IPY_MODEL_0cde3b3731e548209330c4ed68c3ebbe","IPY_MODEL_f7829974d77a469786ee3b99fc7508a4"],"layout":"IPY_MODEL_2805b644dcce45d8941ef373be17b3ab"}},"6fa53312a1a747ac89d8ef9ff5655a89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b37a8df63c784b9686ce75dfba20f11b","placeholder":"​","style":"IPY_MODEL_9baa05b728f84d26be3cd11081e9b4f1","value":"Downloading (…)okenizer_config.json: 100%"}},"70a663d6153a432590a706d665c6c098":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"73370adca3974457a68e15b07a0402d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76b99336d7654df48e9b6757fbf7a9ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c857ab6cd3547ca8a8e02f77b13bbcb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cde5ee78d574b0a9014df9b56088f02":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dc5b02f36304479b9e8c13848df3c7d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7dd44bdda7724144955a984dda977f17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef72c49a741349d8a438bf8ab6e5fb77","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd59975ac25046cea0768719f54def34","value":53}},"7f86a0883c704145a6336b3215dc7222":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b090400020e484eb6cc047cf2aa36db","placeholder":"​","style":"IPY_MODEL_69e43c11e49449fa8679e14f3972566f","value":"Downloading (…)b20bca8e1d/vocab.txt: 100%"}},"843b41830efc4740a03585dbd2f46d08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1507d4d8d84f4b58919a0a527dddc2ca","placeholder":"​","style":"IPY_MODEL_2af40aafb6e94b029a5794265ca4e6ad","value":"Downloading (…)e1d/data_config.json: 100%"}},"862e2e145f9c482ba79009a8e0c17bf1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9918ba9f61674ac684e3d576991fcdf5","max":466021,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7dc5b02f36304479b9e8c13848df3c7d","value":466021}},"8664200eacb540a893522b73eb08efb8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_92bc36549935417a817df97499f90e4c","max":39265,"min":0,"orientation":"horizontal","style":"IPY_MODEL_393bf1308809482da56e4c47c9a02f7f","value":39265}},"8aeadeebe25a417fa8159a453eae90ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f242e29d8870458fa574c029d727dbf8","placeholder":"​","style":"IPY_MODEL_4f984c50813a4c6c9f8f7b5f4debf52d","value":"Downloading (…)0bca8e1d/config.json: 100%"}},"8ded8735767140db9ffd760aca204307":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e93bcf61b874226ba75ac166c2b5d84":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f69bbf81d524cd1858b429cfdcf90f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"909daed29b91479cb960d637f6de31ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6070cfde65124e9e908219044e2abd43","IPY_MODEL_602eb03787b1446eade6e083ec913f60","IPY_MODEL_083391f721584cc89829bc9065d18119"],"layout":"IPY_MODEL_1ba315543b134766bfd54c14e96170b8"}},"92bc36549935417a817df97499f90e4c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"963a68083a004228b0d16d05a4e7f3f4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9859969992ab4a23aa4603977fecff7f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98b29bc0c10f49a3845b0b7fbfa25fe4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68adff24ec7f4fd59d9100c3d1313a65","placeholder":"​","style":"IPY_MODEL_c97a6ef027414c65ac665fe86d4a68d0","value":" 363/363 [00:00&lt;00:00, 27.0kB/s]"}},"9918ba9f61674ac684e3d576991fcdf5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9935324c5417467c89f02449fc924c3c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e93bcf61b874226ba75ac166c2b5d84","max":13123,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0c114b71608d4b15a5ac635c80f13440","value":13123}},"9a01745325e64a20b8d7afdbf842baeb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7ca5ff6fe3c4709bfc54b9d0b30f9b0","placeholder":"​","style":"IPY_MODEL_6967bcad3f3942b4aa683a30aa9335e3","value":"Downloading (…)ce_transformers.json: 100%"}},"9ac7f9557261454bab30654c3ac42e75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b70527ac3104a2ea150df8a501eefb4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9baa05b728f84d26be3cd11081e9b4f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9de38d96b73447aa8e82186558ead4b0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1545436a1b24e7dbb8a7649f043f51d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a38d9789009c4eb9af2ab6eb1c084675":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa3caed35cad44e59099d3ebaf96e3bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa6062fde486403eb74a93c36c76d7a9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aac62ff40b7742bda6cc627eec331b34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"acc7dce9c87c4f87ad8efa575ef820e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_efbb454e48f94a3da8fab8ff80853eff","max":438011953,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4b715e5b92fb4b99832361e750633c38","value":438011953}},"ad33a616647c4824b8c2c77c92a4d53b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e1c1155323647fc85188532bcb2b076","placeholder":"​","style":"IPY_MODEL_4fd5ae96d94f4a4c945d05f7db010de2","value":"Downloading (…)bca8e1d/modules.json: 100%"}},"ae4ff40c1a3145909d39521e4df397ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af42eadb88af410b939b36cdeb2c5798":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1712857ecdd457d812ea15093ac52e4","placeholder":"​","style":"IPY_MODEL_cede7be3be494db4a88f38f8e3cbbd1a","value":" 116/116 [00:00&lt;00:00, 5.53kB/s]"}},"b09e2dae23db413ca3043254f7dff292":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b13b0e0ef95847058b2ed145f5f1e5fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_43859ef9bdb04f938e21d5d347b78e6b","IPY_MODEL_1cb4d447392b470fb1133a6695bc1327","IPY_MODEL_11038e9233654ca381788e372596ea06"],"layout":"IPY_MODEL_cae36db61aa645d58e644cf2a8f7d8bf"}},"b29dfe2ce98246fa971f8eb399271cc4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b37a8df63c784b9686ce75dfba20f11b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b550b2e099f54ba9b87b1d92b447c0ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9158fc24d8a4519a1948416db9ea84f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ded8735767140db9ffd760aca204307","max":231536,"min":0,"orientation":"horizontal","style":"IPY_MODEL_409084e00c314649b0311c24a2e3eb35","value":231536}},"ba76d45f15324a2c87dfc5a0781f2ad2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd59975ac25046cea0768719f54def34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bfab32bf824c437fb37e909cd1f334f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9de38d96b73447aa8e82186558ead4b0","placeholder":"​","style":"IPY_MODEL_9ac7f9557261454bab30654c3ac42e75","value":"Downloading (…)cial_tokens_map.json: 100%"}},"c97a6ef027414c65ac665fe86d4a68d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cae36db61aa645d58e644cf2a8f7d8bf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb3ba136cdc2465c8e058725fe920f2b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd97c277505f433e9aae1c35e9fbc881":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cdd59cf9222d4bbbbbd66b3b3fa8f5c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e724e404d3354f4ebc1f29cb28dfc25b","placeholder":"​","style":"IPY_MODEL_536f121fe07c412ba017a251e52da0b2","value":" 39.3k/39.3k [00:00&lt;00:00, 483kB/s]"}},"cede7be3be494db4a88f38f8e3cbbd1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d42b801510d8430f89d47904cc7acd58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e2cd0fb66eea4f0a8179b4a0fccf1680","IPY_MODEL_acc7dce9c87c4f87ad8efa575ef820e4","IPY_MODEL_3c05158f17bf495b8edb5cafc8331ff9"],"layout":"IPY_MODEL_486c950fe90d4035810220dd9c3539f4"}},"d5e94c3771f14948ad55ca0c05806bab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9dab577cb8b4a4088bff883dc410a8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dbfb5c7191884f118d733c8c64d173ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1712857ecdd457d812ea15093ac52e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1f99a3aa74d4802b969362dfefdbe0f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2cd0fb66eea4f0a8179b4a0fccf1680":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35e52f32fc2248fe947ad4ee34709b8c","placeholder":"​","style":"IPY_MODEL_1e07453fd8df480a8efdd3550f914896","value":"Downloading pytorch_model.bin: 100%"}},"e3e5973a726840c68087247e4f7d6d34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc72ca2311444e81a3c0174b6c25d840","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0771873723304418bb3e37e31ef822c2","value":239}},"e724e404d3354f4ebc1f29cb28dfc25b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea43b5060c234d6bb7f6ea73bf5d9f57":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae4ff40c1a3145909d39521e4df397ce","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_120cf0fe31e1446cb2a9966f818d1e9e","value":349}},"ea9550f524124539be002af02a679256":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eacfe6cc2a6c458c92ad5ef73c69d15f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef4a68cae2b24be7b0070e3c579e4de1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef72c49a741349d8a438bf8ab6e5fb77":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efbb454e48f94a3da8fab8ff80853eff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f242e29d8870458fa574c029d727dbf8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2752078a3d14dabae99dfc7bf0e3dcc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eacfe6cc2a6c458c92ad5ef73c69d15f","placeholder":"​","style":"IPY_MODEL_73370adca3974457a68e15b07a0402d8","value":" 232k/232k [00:00&lt;00:00, 1.44MB/s]"}},"f55030cbc48645d6bdcc50e6796bf5bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f625ef8b52df48cba3a31fa2ddf040f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f654477856014076b6f39c985d227c88":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7829974d77a469786ee3b99fc7508a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b29dfe2ce98246fa971f8eb399271cc4","placeholder":"​","style":"IPY_MODEL_aa3caed35cad44e59099d3ebaf96e3bb","value":" 571/571 [00:00&lt;00:00, 24.2kB/s]"}},"f7ca5ff6fe3c4709bfc54b9d0b30f9b0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7e1b3ce26cd41d88a5b1d5ec3f712d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5e94c3771f14948ad55ca0c05806bab","placeholder":"​","style":"IPY_MODEL_fcbc2c602fdc435db7bf2d44fd9eafd8","value":"Downloading (…)nce_bert_config.json: 100%"}},"f95c6ebae9bd4423bdcfc908533f564b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7f86a0883c704145a6336b3215dc7222","IPY_MODEL_b9158fc24d8a4519a1948416db9ea84f","IPY_MODEL_f2752078a3d14dabae99dfc7bf0e3dcc"],"layout":"IPY_MODEL_4f0a345d1ec04a4593777990ea134c5a"}},"fa321a6c32de4dbabfb2f3af2eae3eaa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc72ca2311444e81a3c0174b6c25d840":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcbc2c602fdc435db7bf2d44fd9eafd8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
